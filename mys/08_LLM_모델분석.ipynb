{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EEVE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/teddylee777/langserve_ollama/tree/main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install huggingface-hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 터미널에 실행\n",
    "# huggingface-cli download heegyu/EEVE-Korean-Instruct-10.8B-v1.0-GGUF ggml-model-Q5_K_M.gguf --local-dir /home/alpaco/mys/projects/news/datas/ollama/gguf/EEVE --local-dir-use-symlinks False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelfile 파일 생성하고 아래 내용 복사 붙여넣기\n",
    "# default 설정입니다. \n",
    "\n",
    "\n",
    "# 여기서부터 주석 해제하고 복 붙\n",
    "# FROM ggml-model-Q5_K_M.gguf\n",
    "\n",
    "# TEMPLATE \"\"\"{{- if .System }}\n",
    "# <s>{{ .System }}</s>\n",
    "# {{- end }}\n",
    "# <s>Human:\n",
    "# {{ .Prompt }}</s>\n",
    "# <s>Assistant:\n",
    "# \"\"\"\n",
    "\n",
    "# SYSTEM \"\"\"A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions.\"\"\"\n",
    "\n",
    "# PARAMETER stop <s>\n",
    "# PARAMETER stop </s>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FROM ggml-model-Q5_K_M.gguf\n",
    "\n",
    "# TEMPLATE \"\"\"{{- if .System }}\n",
    "# <s>{{ .System }}</s>\n",
    "# {{- end }}\n",
    "# <s>Human:\n",
    "# {{ .Prompt }}</s>\n",
    "# <s>Assistant:\n",
    "# \"\"\"\n",
    "\n",
    "# SYSTEM \"\"\"주식 종목 코드와 뉴스 기사를 입력 받으면 해당 종목 코드를 위주로 요약합니다.\"\"\"\n",
    "\n",
    "# PARAMETER stop <s>\n",
    "# PARAMETER stop </s>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FROM ggml-model-Q5_K_M.gguf\n",
    "\n",
    "# TEMPLATE \"\"\"{{- if .System }}\n",
    "# <s>{{ .System }}</s>\n",
    "# {{- end }}\n",
    "# <s>Human:\n",
    "# {{ .Prompt }}</s>\n",
    "# <s>Assistant:\n",
    "# \"\"\"\n",
    "\n",
    "# SYSTEM \"\"\"Assistant는 한국어만 사용합니다.\"\"\"\n",
    "\n",
    "# PARAMETER stop <s>\n",
    "# PARAMETER stop </s>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FROM ggml-model-Q5_K_M.gguf\n",
    "\n",
    "# TEMPLATE \"\"\"{{- if .System }}\n",
    "# <s>{{ .System }}</s>\n",
    "# {{- end }}\n",
    "# <s>Human:\n",
    "# {{ .Prompt }}</s>\n",
    "# <s>Assistant:\n",
    "# \"\"\"\n",
    "\n",
    "# PARAMETER stop <s>\n",
    "# PARAMETER stop </s>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 명령쉘에 실행\n",
    "# ollama create [사용할모델명] -f [Modelfile 경로]\n",
    "# ollama create EEVE-Korean-10.8B -f /home/alpaco/mys/projects/news/datas/ollama/gguf/EEVE/Modelfile\n",
    "# ollama create MoonYoungSik -f /home/alpaco/mys/projects/news/datas/ollama/gguf/EEVE/Modelfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                    \tID          \tSIZE  \tMODIFIED      \n",
      "MoonYoungSik:latest     \t0a4c10719ba8\t7.7 GB\t3 minutes ago\t\n",
      "EEVE-Korean-10.8B:latest\t0a4c10719ba8\t7.7 GB\t9 hours ago  \t\n",
      "gemma2:latest           \tff02c3702f32\t5.4 GB\t12 days ago  \t\n"
     ]
    }
   ],
   "source": [
    "!ollama list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 명령쉘에 실행\n",
    "# ollama run EEVE-Korean-10.8B\n",
    "\n",
    "# 컨트롤+D 누르면 종료됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "eeve= ChatOllama(model= 'EEVE-Korean-10.8B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 18977 글자 가장 긴 뉴스\n",
    "context = ''\"- 40명의 건강한 자원봉사자들이 두 곳에서 진행되는 시험에 참가  - 전임상 동물 시험에서는 희망적인 면역 반응을 보여  - 전 세계 협업사, 파트너와 자금 지원사들로 구성된 연합체를 통해 빠른 진행이 가능  (플리머스미팅, 펜실베이니아주 2020년 4월 6일 PRNewswire=연합뉴스) 이노비오파마슈티컬스[INOVIO Pharmaceuticals, Inc. (나스닥:INO)]는 COVID-19 감염병 예방을 위해 설계된 DNA 백신 후보인 동사 INO-4800의 임상시험계획(IND) 신청을 미국 식품의약처가 받아들여 건강한 자원봉사자들이 참가하는 INO-4800의 1상 시험을 이번 주에 시작할 수 있게 되었다고 오늘 발표했다. 첫 도스가 오늘 투여될 계획이다.  이노비오 사장 겸 CEO인 J. 조셉 김 박사는 \"\"이번 일은 전 세계가 벌이고 있는 COVID-19와의 싸움에서 커다란 진전\"\"이라면서 \"\"COVID-19 팬더믹은 안전하고 효과적인 백신이 새롭게 개발되지 않는다면 사람들의 생명과 생계를 계속 위협할 것이다. 또한 COVID-19 백신을 신속하게 개발하고 1상 시험에 투입하는 것은 당사 DNA 의약품 플랫폼의 힘을 보여준다. 당사의 헌신적인 직원, 파트너와 자금 지원자들은 지난 1월 초에 동 바이러스의 유전자 서열이 밝혀진 이후 가동되었으며, INO-4800을 이번 1상 연구를 거쳐 계획된 효능 시험으로 빠르게 진전시킬 수 있도록 계속 불철주야 일하고 있다\"\"고 말했다.  리차드 햇체트 전염병대비혁신연합(CEPI) CEO는 \"\"이번 일은 전 세계가 임하고 있는COVID-19 백신 개발 노력에 있어 중요한 진전\"\"이라면서 \"\"이노비오의 DNA 백신 플랫폼은 CEPI가 COVID-19 예방 백신 후보 개발을 위해 처음 선정했던 기술 중 하나였다. 동사의 백신 후보가 임상 안전성 시험으로 신속하게 진전되어 기쁘다. 향후 12개월에서 18개월 안에 COVID-19 백신을 생산하는 것은 과학적 과제일 뿐만 아니라 새로운 수준의 협업과 투자가 관련 업계와 정부에서 이루어져야 할 일이다. 안전하고, 효과적이며 세계 전역에서 사용할 수 있는 백신을 확보할 때까지는 여전히 가야 할 길이 멀지만 오늘 우리는 그 여정의 중요한 이정표에 도달했다\"\"고 말했다.  INO-4800의 1상 연구에는 40명의 건강한 성인 자원봉사자들이 펜실베이니아주 필라델피아(펜실베이니아대학 페렐만의대)와 미주리주 캔자스시티(파마슈티컬리서치센터)에 등록될 예정인데 그 두 곳에서는 이미 가능성 있는 참가자들에 대한 선별 작업이 시작되었다. INO-4800 연구에 필요한 물자들이 지난주 그 두 곳에 도착했다. 모든 참가자에게는 4주 간격으로 두 도스가 투여되며 동 연구의 첫 면역 반응 및 안전성 데이터는 늦여름에 나올 것으로 예상된다. 전 세계 규제 당국들이 공유했으며 IND의 한 부분으로 제출되었던 전임상 데이터는 복수의 동물 시험에서 희망적인 면역 반응 결과를 보여주었다. 과제 연구 등 추가적인 전임상 시험이 이번 1상 시험과 병행하여 계속될 예정이다.  이노비오의 규제 업무 담당 선임부사장 아미 샤 브라운 박사는 \"\"자금을 받은 10주 만에 전임상 데이터가 확보된 새로운 백신을 개발하고 제조하여 첫 인체 시험을 진행하는 것은 이노비오와 우리 협업자들에게 중요한 이정표\"\"라고 말했다.  지금까지, 이노비오의 COVID 백신에 대한 전임상 데이터는 그 역시 코로나바이러스가 일으키는 중동호흡기증후군(MERS)에 대하여 당사가 완료한 1상 백신 연구의 결과와 일치하는데, 동 1상 연구에서 이노비오의 DNA 백신은 인체가 잘 견뎌냈으며 연구 참가자들의 95%가 높은 수준의 항체 반응을 보였고 거의 90%에 이르는 참가자들은 광범위한 T 세포 반응을 나타낸 바 있었다. 동 시험에 사용된 이노비오의 DNA 백신(INO-4700)에 대한 장기 항체 반응은 인체 투여 이후 60주를 유지했다.  이노비오는 1상 연구의 첫 안전성 및 면역원성 데이터가 입수되는 대로 INO-4800의 2상 효능 연구를 가능한 한 빨리 진행할 계획이다. 이노비오는 현재 진행 중인 1상 및 계획된 2상 시험을 지원하기 위해 자금 확보 10주 만에 INO-4800 수천 도스를 제조했다. 그와 동시에 이노비오는 INO-4800 제조의 스케일업을 위해 노력하고 있다. 이노비오는 추가적인 시험과 긴급 사용을 위해 올해 말까지 백만 도스분의 백신을 확보할 계획이며 관련 규제 당국의 지침과 자금 조성이 진행 중이다.  펜실베이니아 의대 교수 겸 동 부속 병원 감염병 전문의로서 본 연구의 주임 조사관인 파블로 테바스는 \"\"본 초도 연구의 참가자들이 빠르게 등록될 것으로 예상한다\"\"면서 \"\"이 팬더믹으로부터 수많은 사람을 가능한 한 빨리 보호할 수 있도록 자신들이 할 수 있는 일을 하기 원하는 사람들이 이 백신에 대해 엄청난 관심을 보였다\"\"라고 말했다.  와이스타연구소 백신면역치료센터 원장 겸 동 연구소 수석부소장인 데이비드 B. 와이너 박사는 \"\"임상 시험에 적용되는 이 DNA 기술의 일관성과 결합된 이노비오의 리더십과 동사 직원들의 경험은 본 프로그램의 주요 자산으로 계속 남을 것\"\"이라고 말했다.  이노비오는 INO-4800을 빨리 발전시키기 위해 협업자, 파트너와 지금 지원자들로 구성된 연합체를 결성했다. 와이스타연구소 과학자팀이 핵심적인 연구의 공헌을 했다. 이노비오 프로그램은 전염병대비혁신연합(CEPI)과 빌앤드멜린다게이츠재단으로부터 넉넉한 자금 지원을 받았다. 진원생명과학(KSE: 011000)가 그 전체 지분을 갖고 있는 자회사로서 지난 13년 동안 이노비오의 제조 파트너인 VGXI가 INO-4800 플라스미드 임상 제품의 신속한 제조, 검사 및 공급을 가능케 했다. 또한 미 국방성(DOD)이 이노비오의 협업사 올로지바이오서비시즈에 자금을 지원하여 INO-4800의 추가 도스분을 제조토록 했다.  이노비오의 DNA 의약품 플랫폼  이노비오는 HPV 관련 질병, 암 그리고 전염병대비혁신연합(CEPI)의 기부금을 통해 개발되고 있으며 코로나바이러스가 일으키는 MERS 및 COVID-19 등 감염병에 초점을 맞춰 개발하고 있는 15건의 DNA 의약품 임상 프로그램을 진행하고 있다. DNA 의약품은 컴퓨터 시퀀싱 기술을 통해 합성하고 재조직하며 인체 내에 특정한 면역 대응력을 만들어 내도록 설계된 작은 원의 이중 가닥 DNA인 최적화 DNA 플라스미드들로 구성된다.  이노비오의 DNA 의약품들은 최적화된 플라스미드들을 셀렉트라(CELLECTRA(R))라는 전용 휴대형 스마트 주사기를 사용하여 근육내 및 피부내 세포에 직접 주입한다. 셀렉트라(R)는 짧은 전기 펄스를 이용하여 세포 안에 다시 메꿀 수 있는 구멍을 작게 내서 플라스미드들이 들어갈 수 있도록 함으로써 기타의 DNA와 mRNA 방식에 있는 핵심적인 한계를 해결한다. 동 플라스미드들은 일단 세포 안에 들어가면 해당 세포가 갖고 있는 기제로 인해 코드화된 항원을 생성한 다음 면역 반응을 일으킨다. DNA 의약품은 셀렉트라 기기를 통해 인체 세포 안에 직접 주입되며, 세포 안에 주입된 동 의약품은 즉각 면역 반응을 일으킬 수 있다. 이노비오의 DNA 의약품들은 어떤 방식으로도 한 개인이 갖고 있는 DNA에 간여하거나 변화를 가하지 않는다. 이노비오의 DNA 의약품 플랫폼의 장점은 DNA 의약품들을 빠르게 개발하고 제조할 수 있는 능력, 동 의약품의 저장과 운송 과정에서 냉동이 필요하지 않는 제품들의 안정성, 튼튼한 면역 반응, 임상 시험 과정에서 나타났던 안전성 및 인용성 등이다.  이노비오는 다양한 임상 시험 과정에서 6천 건 이상의 처방으로 이노비오의 시험용 DNA 의약품이 투여된 2천 명 이상의 환자들을 통해 긴급한 전 세계적 보건 니즈를 충족하는 DNA 의약품 후보를 신속하게 만들어 낸 강력한 실적을 보유하고 있다.  이노비오  이노비오는 HPV, 암과 감염병 등에 속한 질병들로부터 사람들을 치료, 간호 및 보호하기 위해 정밀하게 설계된 DNA 의약품의 신속한 출시에 초점을 맞추고 있는 바이오테크 회사이다. 이노비오는 전용 스마트 기기를 통해 DNA 의약품을 인체 피부 안에 직접 주입하여 강하고 내성 높은 면역 반응을 생성한 임상 결과를 보여왔던 최초이자 유일한 기업이다. 구체적으로 말하면, 이노비오의 대표 의약품 후보인 VGX-3100은 현재 전암성 자궁이형성증의 3상을 진행 중이며 고위험 HPV 16과 18을 2b상에서 파괴하고 제거했다. 고위험 HPV는 자궁암의 70%, 항문암의 90%, 여성기암의 69%를 일으킨다. 또한 HPV 관련 암과 HPV 관련 희귀 질병인 재발성 호흡기 유두종(RRP), HPV와 무관한 암들인 다형성교아종(GBM) 및 전립선암을 표적으로 하는 프로그램의 개발뿐만 아니라 지카, 라사열병, 에볼라, HIV 그리고 코로나바이러스가 일으키는 MERS와 COVID-19 질병 등 외부 자금을 지원받는 감염병의 DNA 백신 개발 프로그램도 진행 중이다. 파트너와 협업 기관들에는 애드백신, 아폴로바이오코포레이션, 아스트라제네카, 빌앤드멜린다게이츠재단, 전염병대비혁신연합(CEPI), 방위고등연구계획국(DARPA)/DOD, 진원생명과학/VGXI, HIV백신시험네트워크, 의료CBRN국방컨소시엄(MCDC), 국립암연구소, 국립보건원, 국립알러지전염병연구소, 올로지바이오서비시즈, 플럼라인생명과학, 리제네론, 로슈/제넨텍, 펜실베이니아대학, 월터리드육군연구소와 와이스타연구소가 있다. 또한 이노비오는 이사회에 여성을 20% 이상 참여시키는 회사들에 주는 2020 위민온보드 \"\"W\"\" 데지그네이션 상을 받은 자랑스러운 기업이기도 하다. 상세 정보가 필요할 경우 www.inovio.com을 방문하기 바란다.  연락처:  미디어: Jeff Richardson, 267-440-4211, jrichardson@inovio.com  투자자: Ben Matone, 484-362-0076, ben.matone@inovio.com  이 언론 배포문에는 임상 시험의 착수 계획 및 실행과 동 시험에서 나오는 데이터의 활용성과 그 시점, 당사의 제조 및 상용화 전략과 전술이 포함된 상용화 활동뿐만 아니라 INO-4800 등 DNA 의약품 후보의 개발을 위한 당사 계획, 당사의 연구개발 프로그램에 대한 당사의 기대 등 당사 사업에 관련된 미래 예측성 언급이 들어있다. 실제의 사건과 결과는 임상 전 연구, 임상 시험과 제품 개발 프로그램, 제조 및 상용화 활동과 그 성과, 주입 메커니즘인 전기천공 기술의 안전성과 효능을 증명하거나 효과적인 DNA 의약품 개발을 위해 지속 중인 연구 활동을 지원할 수 있는 자금의 확보 가능성, DNA 의약 제품 파이프라인을 지원할 수 있는 당사의 능력, 당사가 라이선스하는 제품의 개발과 상용화 일정을 달성하고 당사에 미래의 대금과 로열티를 지불할 수 있도록 제품을 판매할 수 있는 당사 협업사들의 능력, 당사 자본 조달 리소스의 적정성, 당사 혹은 당사 협업사들이 목표로 하는 질병을 치료할 수 있으며 당사 혹은 당사 협업사들이 개발을 희망하는 요법 혹은 치료제보다 효능이 좋거나 비용 효율성이 높은 다른 요법 혹은 치료제의 출현 혹은 출현 가능성, 제품의 생산물 책임에 관련된 문제, 특허와 관련되며 특허 혹은 특허 라이선스가 해당 기술을 타사가 사용하지 못하도록 막는 의미 있는 보호 장치를 당사에 제공할 수 있는지, 그러한 소유권이 강제되거나 방어되고 혹은 타사의 권리를 침해하거나 침해가 주장되고 혹은 소유권 무효 주장에 대항할 수 있는지와 당사가 필요 자금을 조달하거나 고발, 보호 혹은 방어하는 데 필요할지도 모를 기타의 중요한 리소스에 전념할 수 있는지에 관련된 문제, 기업 지출 수준, 잠재적인 기업 혹은 기타 파트너들에 의한 당사 기술의 평가, 자금 시장 상황, 정부 보건 정책의 영향 그리고 2019년 12월 31일 마감 연도의 10-K 양식 당사 결산보고서와 당사가 때때로 작성하여 증권거래위원회에 제출한 기타 자료 등이 포함된 다수 요소의 결과로서 여기에 나와 있는 예측과는 다를 수 있다. 당사 파이프라인에 있는 제품 후보가 성공적으로 개발, 제조되거나 상용화되며, 임상 시험의 최종 결과가 라이선스된 제품의 판매에 필요한 규제 당국의 승인을 받는 데 적합하거나 여기에 나와 있는 미래 예측성 정보가 정확한 것으로 증명된다는 보장은 없다. 미래 예측성 언급은 이 배포문의 시점에 한해 유효하며, 당사는 법률이 요구하는 것을 제외하고 이들 언급을 업데이트하거나 개정할 책임을 지지 않는다.  출처: INOVIO Pharmaceuticals, Inc.  INOVIO Initiates Phase 1 Clinical Trial Of Its COVID-19 Vaccine and Plans First Dose Today  - Up to 40 Healthy Volunteers To Participate at Two Trial Locations  - Preclinical Animal Studies Show Promising Immune Responses  - Rapid Advancement Possible Through a Global Coalition of Collaborators, Partners, and Funders  PLYMOUTH MEETING, Pennsylvania, April 6, 2020 /PRNewswire/ -- INOVIO Pharmaceuticals, Inc. (NASDAQ:INO) today announced that the U.S. Food and Drug Administration has accepted the company's Investigational New Drug (IND) application for INO-4800, its DNA vaccine candidate designed to prevent COVID-19 infection, paving the way for Phase 1 clinical testing of INO-4800 in healthy volunteers beginning this week. The first dosing is planned for today.  Dr. J. Joseph Kim, INOVIO's President and CEO, said, \"\"This is a significant step forward in the global fight against COVID-19. Without a new safe and effective vaccine, the COVID-19 pandemic is likely to continue to threaten lives and livelihoods. It also demonstrates the power of our DNA medicines platform to rapidly develop and advance a vaccine for COVID-19 into Phase 1 clinical testing. Our dedicated team of staff, partners and funders have been mobilized since the genetic sequence of the virus became available in early January and continues to work around the clock to ensure that we are rapidly advancing INO-4800 through this Phase 1 study towards planned efficacy trials.\"\"  Richard Hatchett, CEO of the Coalition for Epidemic Preparedness Innovations (CEPI), said, \"\"This development is an important step forward in the world's search for a COVID-19 vaccine. INOVIO's DNA vaccine platform was one of the first technologies selected by CEPI to develop a vaccine candidate against COVID-19. We are pleased to see the rapid advancement of their vaccine candidate into clinical safety testing. Producing a COVID-19 vaccine within the next 12 to 18 months is not only a scientific challenge; it will also require new levels of collaboration and investment across industry and government. There is still a long road ahead before we have a safe, effective, and globally accessible vaccine ready for broader use, but today we have reached an important milestone on that journey.\"\"  The Phase 1 study of INO-4800 will enroll up to 40 healthy adult volunteers in Philadelphia, PA (at the Perelman School of Medicine at the University of Pennsylvania) and Kansas City, MO (at the Center for Pharmaceutical Research), where screening of potential participants has already begun. Study supplies of INO-4800 arrived at the sites last week. Each participant will receive two doses of INO-4800 four weeks apart, and the initial immune responses and safety data from the study are expected by late summer. Preclinical data, which have been shared with global regulatory authorities and submitted as part of the IND, have shown promising immune response results across multiple animal models. Additional preclinical trials, including challenge studies, will continue in parallel with the Phase 1 clinical trial.  Dr. Ami Shah Brown, INOVIO's Senior Vice President of Regulatory Affairs said, \"\"Development and manufacture of a new vaccine with preclinical data to support a first-in-human trial in ten weeks from funding is a major milestone for INOVIO and our collaborators.\"\"  To date, preclinical results for INOVIO's COVID vaccine have been consistent with our completed Phase 1 vaccine study for Middle East Respiratory Syndrome (MERS), also caused by a coronavirus, in which INOVIO's DNA vaccine was well tolerated and induced high levels of antibody responses in 95% of subjects, while also generating broad-based T cell responses in nearly 90% of study participants. Durable antibody responses to its DNA vaccine (INO-4700) used in that trial were maintained through 60 weeks following dosing.  Upon attaining initial safety and immunogenicity data from Phase 1 studies, INOVIO plans to advance INO-4800 to Phase 2 efficacy studies as rapidly as possible. In 10 weeks from funding, INOVIO has manufactured thousands of doses of INO-4800 to support on-going Phase 1 and planned Phase 2 clinical trials. In parallel, INOVIO is working to scale up the manufacturing of INO-4800. INOVIO plans to have one million doses of the vaccine available by year-end for additional trials and emergency use, pending appropriate regulatory guidance and funding.  \"\"We anticipate rapid enrollment of this initial study,\"\" said Pablo Tebas, MD, infectious disease specialist and professor of Medicine at the Hospital of the University of Pennsylvania and Principal Investigator of the study. \"\"There has been tremendous interest in this vaccine among people who want to do what they can to help protect the greater public from this pandemic as soon as possible.\"\"  \"\"INOVIO's leadership and the team's experience combined with the consistency of this DNA technology for clinical translation continue to be a major asset for the program,\"\" said Dr. David B. Weiner, Director of the Wistar Institute's Vaccine and Immunotherapy Center and Executive Vice President of the Institute.  INOVIO has assembled a global coalition of collaborators, partners, and funders to rapidly advance INO-4800. The scientific team at the Wistar Institute has provided key research contributions. The INOVIO program has been supported by generous funding from the Coalition for Epidemic Preparedness Innovations (CEPI) and the Bill and Melinda Gates Foundation. VGXI, Inc., a wholly-owned subsidiary of GeneOne Life Science (KSE: 011000) and INOVIO's manufacturing partner for the last 13 years, enabled the expedited manufacture, testing, and release of the INO-4800 plasmid clinical product. The U.S. Department of Defense (DOD) has also funded INOVIO's collaborator Ology Bioservices to manufacture additional doses of INO-4800.  About INOVIO's DNA Medicines Platform  INOVIO has 15 DNA medicine clinical programs currently in development focused on HPV-associated diseases, cancer, and infectious diseases, including coronaviruses associated with MERS and COVID-19 diseases being developed under grants from the Coalition for Epidemic Preparedness Innovations (CEPI). DNA medicines are composed of optimized DNA plasmids, which are small circles of double-stranded DNA that are synthesized or reorganized by a computer sequencing technology and designed to produce a specific immune response in the body.  INOVIO's DNA medicines deliver optimized plasmids directly into cells intramuscularly or intradermally using INOVIO's proprietary hand-held smart device called CELLECTRA(R). CELLECTRA(R) uses a brief electrical pulse to open small pores in the cell reversibly to allow the plasmids to enter, overcoming a key limitation of other DNA and mRNA approaches. Once inside the cell, the plasmids are used by the cell's own machinery to generate specific coded antigens, which then stimulate an immune response. Administration with the CELLECTRA device ensures that the DNA medicine is delivered directly into the body's cells, where it can go to work immediately mounting an immune response. INOVIO's DNA medicines do not interfere with or change in any way an individual's own DNA. The advantages of INOVIO's DNA medicine platform are how fast DNA medicines can be constructed and manufactured, the stability of the products which do not require freezing in storage and transport, and the robust immune response, safety profile, and tolerability that have been demonstrated in clinical trials.  With more than 2,000 patients receiving INOVIO investigational DNA medicines in more than 6,000 applications across a range of clinical trials, INOVIO has a strong track record of rapidly generating DNA medicine candidates to meet urgent global health needs.  About INOVIO  INOVIO is a biotechnology company focused on rapidly bringing to market precisely designed DNA medicines to treat, cure, and protect people from diseases associated with HPV, cancer, and infectious diseases. INOVIO is the first and only company to have clinically demonstrated that a DNA medicine can be delivered directly into cells in the body via a proprietary smart device to produce a robust and tolerable immune response. Specifically, INOVIO's lead candidate VGX-3100, currently in Phase 3 trials for precancerous cervical dysplasia, destroyed and cleared high-risk HPV 16 and 18 in a Phase 2b clinical trial. High-risk HPV is responsible for 70% of cervical cancer, 90% of anal cancer, and 69% of vulvar cancer. Also in development are programs targeting HPV-related cancers and a rare HPV-related disease, recurrent respiratory papillomatosis (RRP); non-HPV-related cancers glioblastoma multiforme (GBM) and prostate cancer; as well as externally funded infectious disease DNA vaccine development programs in Zika, Lassa fever, Ebola, HIV, and coronaviruses associated with MERS and COVID-19 diseases. Partners and collaborators include Advaccine, ApolloBio Corporation, AstraZeneca, The Bill & Melinda Gates Foundation, Coalition for Epidemic Preparedness Innovations (CEPI), Defense Advanced Research Projects Agency (DARPA)/DOD, GeneOne Life Science/VGXI, HIV Vaccines Trial Network, Medical CBRN Defense Consortium (MCDC), National Cancer Institute, National Institutes of Health, National Institute of Allergy and Infectious Diseases, Ology Bioservices, Plumbline Life Sciences, Regeneron, Roche/Genentech, University of Pennsylvania, Walter Reed Army Institute of Research, and The Wistar Institute. INOVIO also is a proud recipient of 2020 Women on Boards \"\"W\"\" designation recognizing companies with more than 20% women on their board of directors. For more information, visit www.inovio.com.  CONTACTS:  Media: Jeff Richardson, 267-440-4211, jrichardson@inovio.com  Investors: Ben Matone, 484-362-0076, ben.matone@inovio.com  This press release contains certain forward-looking statements relating to our business, including our plans to develop DNA medicine candidates, including INO-4800, our expectations regarding our research and development programs, as well as commercialization activities, including the planned initiation and conduct of clinical trials, the availability and timing of data from those trials and our manufacturing and commercialization strategy and tactics. Actual events or results may differ from the expectations set forth herein as a result of a number of factors, including uncertainties inherent in pre-clinical studies, clinical trials, product development programs and manufacturing and commercialization activities and outcomes, the availability of funding to support continuing research and studies in an effort to prove safety and efficacy of electroporation technology as a delivery mechanism or develop viable DNA medicines, our ability to support our pipeline of DNA medicine products, the ability of our collaborators to attain development and commercial milestones for products we license and product sales that will enable us to receive future payments and royalties, the adequacy of our capital resources, the availability or potential availability of alternative therapies or treatments for the conditions targeted by us or our collaborators, including alternatives that may be more efficacious or cost effective than any therapy or treatment that we and our collaborators hope to develop, issues involving product liability, issues involving patents and whether they or licenses to them will provide us with meaningful protection from others using the covered technologies, whether such proprietary rights are enforceable or defensible or infringe or allegedly infringe on rights of others or can withstand claims of invalidity and whether we can finance or devote other significant resources that may be necessary to prosecute, protect or defend them, the level of corporate expenditures, assessments of our technology by potential corporate or other partners or collaborators, capital market conditions, the impact of government healthcare proposals and other factors set forth in our Annual Report on Form 10-K for the year ended December 31, 2019 and other filings we make from time to time with the Securities and Exchange Commission. There can be no assurance that any product candidate in our pipeline will be successfully developed, manufactured or commercialized, that final results of clinical trials will be supportive of regulatory approvals required to market products, or that any of the forward-looking information provided herein will be proven accurate. Forward-looking statements speak only as of the date of this release, and we undertake no obligation to update or revise these statements, except as may be required by law.  Source: INOVIO Pharmaceuticals, Inc.  [편집자 주] 본고는 자료 제공사에서 제공한 것으로, 연합뉴스는 내용에 대해 어떠한 편집도 하지 않았음을 밝혀 드립니다.  ▶코로나19 속보는 네이버 연합뉴스에서 [구독 클릭] ▶[팩트체크] '코로나19' 사실은 이렇습니다▶제보하기\"''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'INOVIO 제약은 COVID-19 DNA 백신 후보 물질인 INO-4800의 제2상 임상 시험을 위한 환자 모집이 시작되었다고 발표하였습니다. 이 연구는 건강한 자원봉사자들을 대상으로 하며, 백신 용량에 따라 참가자들을 세 그룹으로 나눌 예정입니다. 백신 투여 후 1년간 면역원성과 안전성 데이터를 평가할 계획입니다. INO-4800은 임상 시험에서 안전하고 면역 반응을 유도하는 것으로 입증되었으며, 전임상 연구에서는 SARS-CoV-2 바이러스에 대한 중화 항체와 T세포 반응을 효과적으로 생성한다는 것을 확인하였습니다.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = eeve.invoke('('+context+') 글에서 11000 위주로 요약해주세요').content.replace('\\n', ' ').replace('*','').replace('#','') # 답변 저장\n",
    "temp = eeve.invoke(answer+'\\t 위 문장이 긍정문인지 부정문인지 대답하세요 당신의 대답은 ''긍정'' 또는 ''부정'' 두 단어 중 하나로만 대답 ').content.replace('\\n', ' ').replace('*','').replace('#','') # 답변 저장\n",
    "answer = eeve.invoke(answer+'에서 11000가'+temp+'이유는?').content.replace('\\n', ' ').replace('*','').replace('#','') # 답변 저장\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "context2 = '[파이낸셜뉴스] 두산그룹주가 장 초반 일제히 급락하고 있다. 25일 오전 9시 51분 기준 두산밥캣의 주가는 전 거래일 대비 9.56% 하락한 4만2550원에 거래되고 있다. 이 시간 두산에너빌리티 [ 15,770 하향 (-2.89%) ] 토론공시는 3.38%, 두산로보틱스 [ 78,600 상향 (+6.36%) ] 토론공시는 8.52% 하락 중이다. 두산도 전장 대비 10.31% 하락한 17만4900원에 거래 중이다.전날 금융감독원이 두산로보틱스에 합병과 주식의 포괄적 교환·이전 증권신고서에 대해 정정신고서를 제출하라고 요구하면서 불확실성이 커진 탓으로 풀이된다.앞서 두산그룹은두산로보틱스와 두산에너빌리티 간 인적분할·합병, 두산밥캣과 두산로보틱스 간 포괄적 주식교환 등을 통해 두산밥캣을 두산로보틱스의 완전 자회사로 이전하는 사업 구조 개편안을 발표했다.하지만 안정적인 캐시카우인 두산밥캣과 적자기업 두산로보틱스의 합병비율을 1대 0.63으로 정하면서 소액주주의 반발이 터져 나오기도 했다.이날 신한투자증권 이동헌 연구원은 \"두산로보틱스와의 시너지는 장기 관점에서 바라본 것이고, 단기적으로는 지분 교환 및 합병에 대한 두산밥캣의 가치 희석 우려가 더 크게 작용한다\"며 \"주식 교환 무산 시 일부 주가 회복이 예상되나 업황 둔화와 신뢰 저하로 회복에 시간이 필요하다. 주식 교환에 성공해도 로보틱스의 가치를 지지하면서 시너지를 보이기에는 시차가 존재한다\"고 꼬집었다.hippo@fnnews.com 김찬미 기자Copyrightⓒ 파이낸셜뉴스. 무단전재 및 재배포 금지.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'파이낸셜뉴스에 따르면, 두산그룹의 주가가 장 초반 크게 하락하고 있습니다. 금융감독원의 두산로보틱스 합병과 주식 교환 및 이전 증권 신고서에 대한 정정신고 요구로 인해 불확실성이 커지고 있는 것이 원인입니다. 두산그룹은 인적분할, 합병 및 주식을 통한 사업 구조를 재편하려는 계획을 가지고 있었습니다만, 현금 창출원인 두산밥캣과 적자 기업인 두산로보틱스의 합병 비율(1:0.63)에 대해 소액주주들의 반발을 샀습니다. 신한투자증권의 이동헌 연구원은 단기적으로 주식 교환이 무산될 경우 일부 주가 회복은 가능하지만 업황 둔화와 신뢰 저하로 인해 시간이 필요하다고 전망하고 있습니다.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = eeve.invoke(f'({context2}) 글에서 두산그룹 위주로 요약해주세요').content.replace('\\n', ' ').replace('*','').replace('#','') # 답변 저장\n",
    "emotion = eeve.invoke(f'{answer}\\t 위 문장이 긍정문인지 부정문인지 대답하세요 당신의 대답은 ''긍정'' 또는 ''부정'' 두 단어 중 하나로만 대답 ').content.replace('\\n', ' ').replace('*','').replace('#','') # 답변 저장\n",
    "answer = eeve.invoke(f'{answer}에서 두산그룹이 {emotion}인 이유는?').content.replace('\\n', ' ').replace('*','').replace('#','') # 답변 저장\n",
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gemma2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 올라마 리눅스 설치 및 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -fsSL https://ollama.com/install.sh | sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 올라마 내부 gemma2 설치 및 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama pull gemma2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama run gemma2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 올라마 + gemma2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "gemma2= ChatOllama(model= 'gemma2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가장 긴 뉴스 8442 글자\n",
    "context = '\"- 급등 계속된 가상화폐 시장, 우울증 양산 - ‘50원에 샀는데 1500원 됐다’..80억 계좌 인증 화면 돌아다녀 - ‘과장님, 회사 그만뒀는데 알고 봤더니 20억을 벌었더라’ - ‘투자하고 있으면 5분마다 스마트폰 확인, 판 사람은 1분마다 확인’ - 정부 규제 나섰지만 시장 특성상 쉽지 않아 CBS 라디오 ''시사자키 정관용입니다'' ■ 방 송 : FM 98.1 (18:30~19:55) ■ 방송일 : 2018년 1월 8일 (월) ■ 진 행 : 정관용 (한림국제대학원대학교 교수) ■ 출 연 : 고란 기자(중앙일보) ◇ 정관용> 새해 들어서도 가상화폐 열풍이 심상치가 않습니다. 가상화폐 투자로 2시간 만에 30억을 벌었다는 사례까지 등장하면서 그 인기가 식을 줄을 모르는데요. 정부의 규제책이 도리어 가상화폐 가치를 높인다 이런 분석까지 있네요. 2018년에도 가상화폐는 계속 오를 것인지. 이건 우리 경제에는 어떤 영향을 미칠 것인지, 중앙일보의 고란 기자, 오늘은 스튜디오에 직접 초대했습니다. 어서 오십시오. ◆ 고란> 안녕하세요. ◇ 정관용> 우리 얼마 전에도 고란 기자랑 인터뷰하면서 가상화폐가 뭔지. 왜 그렇게 오르는지 그런 얘기하면서 이거 언제 급락할지 위험하다. 그런 얘기하고 인터뷰 끝냈던 기억이 나는데 그 후로도 계속 오르는 거 아니에요? ◆ 고란> 오히려 더 과열되고 있다고 볼 수 있죠. ◇ 정관용> 조금 아까 제가 언급한 2시간 만에 30억 벌었다는 것은 입증된 거예요? ◆ 고란> 이게 모 방송에서 지난 토요일에 방송돼서 PD가 인터뷰를 시작하기 전에 찍혔던 금액이 280억인데, 화면에, 모니터상에. 그런데 인터뷰가 끝날 때쯤 2시간이 지나자 그게 310억으로 불어나 있었습니다. ◇ 정관용> 280억 정도 투자하는 큰손이군요, 그 사람은. 전체 그림을 봅시다. 우리나라 시장 규모를 보기 위해서 국내에 거래되는 가상화폐의 종류가 몇 가지 정도 됩니까? ◆ 고란> 이게 종류를 말씀드리기 전에 먼저 거래소 얘기부터 하는 게 맞을 것 같은데요. 국내에 있는 가장 큰 거래소가 기존에는 빗썸이라고 있었는데. ◇ 정관용> 빗썸. ◆ 고란> 그밖에 최근 지난해 10월에 오픈한 게 업비트라는 거래소가 있습니다. ◇ 정관용> 업비트. ◆ 고란> 빗썸이나 코인원, 코빗 등 오래된 거래소, 역사가 1년 이상 된 거래소는 대충 거래할 수 있는 암호화폐가 한 10개 내외 이 정도밖에 안 됩니다. 그런데 이 업비트라고 하는 지난해 10월에 오픈한 거래소는 거래할 수 있는 화폐의 종류가 122종이나 됩니다. 이게 차이가 있죠. ◇ 정관용> 그러면 122종이 다 몇 천만 원씩 하는 건 아니죠? ◆ 고란> 아닙니다. ◇ 정관용> 천차만별인 거죠? ◆ 고란> 소위 ‘동전주’라고 하는 것도 많이 있습니다. ◇ 정관용> 동전주가 뭐예요? ◆ 고란> 주식에서 1000원이 안 되는 종목을 동전주라고 하는데요. ◇ 정관용> 그런 것도 있습니까? ◆ 고란> 이게 사람들이 최근에 열광하는 게, 사실 ‘리플’이라는 종목이 하나 있거든요. 암호화폐가. 그런데 이 코인이 지난해 12월에 이백 몇 원 했었거든요. 280원 정도 했나? 그런데 지금 현재 4500원 정도에 거래되고 있습니다. ◇ 정관용> 그러면 한 달 만에 10배, 20배 이렇게 되네요. ◆ 고란> 네. ◇ 정관용> 그러니까 종목을 가리지 않고 다 오르는 거예요? ◆ 고란> 지금 현재 상황은 정말 말씀하신 대로 종목을 가리지 않고 다 오르고 있고요. 특히나 제가 말씀드린 동전주 있잖아요. 업비트라고 말씀드린 거래소에서 다루는 화폐가 122종이 된다고 하는데 다 우리나라 원화로 살 수 있는 것은 아니고요. 이중에서 원화종목이 35개 정도 있는데 동전주가 기존에는 굉장히 많았거든요. 한 20개 정도 됐었나 그렇게 됐었는데 12월 달에 급등을 하면서 지금 현재 동전주가 1개밖에 안 남았습니다. ◇ 정관용> 다 올랐군요, 그러니까. ◆ 고란> 다 올랐습니다. ◇ 정관용> 그리고 그런 거래소는 전체 몇 군데나 있어요? ◆ 고란> 이게 지금 금융당국에서 파악한 게 사실 파악도 제대로 안 되고 있고요. 대강 파악한 게 30여 곳 된다고 하고 있는데요. 업비트, 말씀드린 빗썸, 그다음에 코인원, 코빗, 코인네스트 이 정도가 유명한 곳들이고요. ◇ 정관용> 거기에 우리 국민 가운데 몇 명 정도가 참여하고 있는 겁니까? ◆ 고란> 이게 말씀드린 빗썸이 12월 말로 회원수가 250만 명 정도 되거든요. 그리고 업비트가 120만 명 정도 되고요. 그 나머지 거래소를 합치면 500만 명 좀 못 되는 건데 이건 단순 합산이고요. 중복 계좌 갖고 계신 분들도 많아서 대충 한 200만 명은 웃돌 것이다 보고 있습니다. ◇ 정관용> 200만 명 이상. ◆ 고란> 네. ◇ 정관용> 하루 거래 액수는 얼마나 됩니까? ◆ 고란> 이게 말씀드린 업비트가 일평균 7조에서 8조 정도 된다고 하거든요. 많을 때는 최대 10조 찍은 날도 있었습니다. ◇ 정관용> 우리나라 주식시장이 하루 거래가 얼마죠? ◆ 고란> 코스닥이 3조~4조 되거든요. ◇ 정관용> 코스닥보다 하루 평균으로 2배 이상. ◆ 고란> 코스닥 거래는 모든 증권사에서 거래되는 거래금액을 다 합친 게 4조, 3조 되거든요. 그런데 여기서 업비트에서 하루에만 10조 찍은 날도 있었고 평균 5조 이상은 찍고요. 그다음에 빗썸도 3~4조 찍고 그래서 나머지 거래소 합치면 일평균 10조 정도는 거래된다고 볼 수 있습니다. ◇ 정관용> 주로 데이 트레이딩 형식으로? ◆ 고란> 그렇게 하신 분들도 많이 있고요. ◇ 정관용> 그런데 빗썸이 제일 유명하다가 갑자기 업비트라고 하는 게 그렇게 유명해진 이유는 뭐예요. 그리고 거기는 그렇게 거래 종목이 많은 것은 또 이유가 뭐예요. ◆ 고란> 첫 번째 종목이 많은 것은 세계적인 거래소 비트렉스라고 있거든요. 거기하고 독점제휴를 해서 비트렉스에 상장된 종목을 그대로 거래할 수가 있습니다. 그렇기 때문에 종목이 상당히 많고요. 그래서 업비트를 이용하시는 분들도 있고요. 옛날에 사고 싶은 종목이 있으면 해외거래소를 이용해야 됐었는데 조금 불편하거든요, 아무래도 다 영어로 돼 있고 하다 보니까. 그런데 지금은 쉽게 거래할 수 있는 거고 그리고 이게 후발주자다 보니까 수수료를 절반 수준으로 다운시켰습니다. 거래할 때 살 때, 팔 때 각각 0. 1%씩 매기는데 여기에는 절반 0. 05%씩이고요. 무엇보다 가장 큰 이유가 업비트가 카카오의 100% 자회사인 케이큐브벤처스가 투자한 두나무라는 회사의 자회사입니다. ◇ 정관용> 복잡하네요. ◆ 고란> 조금 복잡한데요. ◇ 정관용> 카카오의 한 증손자쯤? ◆ 고란> 그렇죠. 정확한 자회사는 아니고 투자회사가 연결되어 있는데 어쨌든 관련돼 있거든요. 그렇다 보니까 카카오톡 플랫폼을 기반으로 해서 회원가입이 됩니다. 저도 회원가입을 해봤는데 저도 카카오톡 가입자고 아마 많은 국민이 카카오톡 가입자일 것 같은데 가입자인 경우에는 클릭 몇 번, 몇 번만 하면 바로 회원가입이 됩니다. ◇ 정관용> 거래소에 회원가입이 쉽더라? ◆ 고란> 쉽고요. 거기에 내가 돈을 입금하고 싶으면 실명계좌만 하면 입금할 수 있습니다. ◇ 정관용> 쉬워서 여기를 더 많이 이용한다 그런 거군요. 그림이 그려지네요. 작년 가을부터 다들 가상화폐, 가상화폐 그러니까 나도 한번 해 볼까. 그런데 그게 어려울 거야. 가만 있어, 카카오톡 하면 된다며 이렇게 된 거군요. ◆ 고란> 그렇죠. 이렇게 코인시장에 11월, 12월에 새로 진입하신 분을 가리켜서 용어로는 코인어린이, 줄여서 코린이, 코린이들. 그래서 업비트에 코린이들이 많다. 그래서 여기서 나타나는 현상이 뭐냐 하면 이게 보통 해외거래소와 국내거래소는 가격차이가 벌어지거든요. 왜냐하면 국내에 투자하시는 분들이 해외에 계좌가 없기 때문에 해외거래소에서 사기가 힘들거든요. 그렇기 때문에 국내에서 더 수요가 많고 해서 더 비싸게 거래됩니다. 그런데 주목할 만한 건 업비트에 코린이들이 많다 보니까 업비트에서 거래되는 가격이 다른 빗썸이나 코인원에서 되는 가격보다 5% 안팎 비싸게 거래됩니다. ◇ 정관용> 더 비싼데도. ◆ 고란> 거기를 삽니다. ◇ 정관용> 초보자니까 다른 데 갈 줄 모르고 그냥 산다. ◆ 고란> 굳이 비교를 안 하시는 거죠. ◇ 정관용> 어쨌든 좀 비싸도 산다는 얘기는 너도 나도 사자는 얘기는 그래도 오른다는 얘기잖아요. ◆ 고란> 그렇게 믿고 계시는 거죠. ◇ 정관용> 그런데 실제 가격 오르고 있잖아요. ◆ 고란> 지금 오르고 있잖아요. ◇ 정관용> 그렇죠, 그러면 정말로 떼돈 버는 사는 사람들이 그렇게 많아요? ◆ 고란> 사실 제가 들은, 저도 각종 암호화폐 커뮤니티에 가서 보면 수익 인증하는 글들이 가끔씩 올라오거든요. 그러면 어떤 특정 종목을 50원에 샀는데 해당 종목이 지금 1500원이 돼서 몇 배를 벌었다. 그래서 80억 계좌가 찍히는 것을 인증하는 화면이 돌아다니고요. 그리고 제 후배의 친구는 같은 부서에 있는 과장님이 회사를 그만뒀는데 알고 봤더니 20억을 벌고 회사를 나가셨다더라 이런 얘기들이 횡행하고 있죠. 이렇게 워낙 억 단위로 버는 수십억, 수백억을 벌었다는 사람이 많기 때문에 내가 투자해서 사실 몇 천만 원을 벌어도 이렇게 돈을 번 사람들까지 우울증에 시달리고 있습니다. ◇ 정관용> 몇 천만 원 벌었는데 우울증? ◆ 고란> 왜냐하면 그때 좀 더 투자했으면 더 벌 수 있었는데 아까운 거죠. 그리고 투자한 사람, 돈을 번 사람도 우울증이고 돈을 못 번 사람들도 우울증입니다. 왜냐하면 투자했으면 돈 벌었을 텐데라고 생각하는 거죠. ◇ 정관용> 나는 그때 50만 원 갖고 시작했는데. ◆ 고란> 맞아요. 그때 만약 500만 원이었다면, 5000만 원이었다면? ◇ 정관용> 그러면 내가 몇 천만원이 아니라 몇 억을 벌었을 텐데 이런 식으로 모두가 다 박탈감이네요. ◆ 고란> 사실 그렇죠. 모두가 다 박탈감. 어쨌든 이렇게 사회 전반적으로 해서 우울증이 확산되고 있다고 해서 이거를 일명 ‘코인 우울증’이라고 부르기도 하더라고요. ◇ 정관용> 그다음 여기에 투자하는 사람들은 지금 워낙 가격변동이 워낙 급변동하고 이거는 거래 시간이 정해져 있는 게 아니잖아요. ◆ 고란> 24시간 거래됩니다. ◇ 정관용> 거의 폐인이 된다는 얘기를 들었어요. 계속 스마트폰만, 컴퓨터만 들여다보고 있는 사람들. ◆ 고란> 그래서 업계에서 떠도는 말 중에 그런 게 있는데 코인 투자하고 있으면 5분마다 스마트폰을 확인하고요. 코인을 팔아도 1분마다 확인한다고 합니다. ◇ 정관용> 내가 판 다음에 또 올랐을까 봐.. ◆ 고란> 그렇죠. 그래서 그런 용어를 심리학적 용어로 포모(fomo)라고 표현하거든요. 피어 오브 미싱 아웃(fear of missing out)인데요. 어떤 큰 이벤트가 벌어졌을 때 내가 거기에 혹시나 소외될 수 있지 않을까라고 해서 그걸 항상 들여다보고 그 시장에 뛰어드는 이런 심리를 말하는데요. 그에 반대되는 게 퍼드(fud. Fear Uncertainty and Doubt)라는 건데 이건 어떤 가격이 급등했을 때 급락할 수 있다는 위험이거든요, 두려움. 그런데 지금 현재 이 시장에서 벌어지는 것은 퍼드보다는 포머. 내가 큰 이벤트 이렇게 큰 돈 벌 수 있는 기회에서 빠지면 어떻게 하나 이런 심리가 지금 더 강해서 다들 뛰어들고 있고 가격도 오르고 있습니다. ◇ 정관용> 그런데 일단 뛰어들면 5분 간격으로, 1분 간격으로 보고 밤에 잠도 못 잔다면서요? 중앙일보 고란 기자(사진=시사자키) ◆ 고란> 저도 사실 초기에 투자를 경험했거든요. 처음 투자를 할 때는 정말 자다가 일어나서 눈 뜨면 핸드폰 확인해서 얼마 됐지 하고 확인하는 게 사실 일이었죠. ◇ 정관용> 누구라도 그렇게 급변동하는 것을 궁금해서 어떻게 참겠어요? ◆ 고란> 그렇죠. ◇ 정관용> 그렇죠? 이 정도로 짧은 시간에 높은 수익을 낸다. 이게 정상입니까? ◆ 고란> 지금 혹시 과거에 주식투자를 해 보셨던 분들은 90년대 말 코스닥 버블 생각하시면 될 것 같아요. 그때 보면 특정 종목 같은 경우에는 한 달 이상 상한가. ◇ 정관용> 매일매일 상한가. ◆ 고란> 그렇죠. 그렇게 기록한 종목들도 있었거든요. 그런 정도의 열기가 있었고 당시에도 대학생들이 너도 나도 주식계좌 열어서 투자하는 열풍이 일었었고요. 지금도 그렇다고 보면 되는데 지금이 더 심각한 것은 거래 시간이 정해져 있지 않다는 것. ◇ 정관용> 그러니까 한밤중까지도. 게다가 지금 설명 들어보면 참가자 숫자도 어마어마하고 거래액수도 어마어마하기 때문에 이거 그냥 일시적이라고 말하기 어려울 것 같아요. 그런데 장이 이렇다 보면 반드시 작전세력이 등장하죠. ◆ 고란> 그렇죠. 특히나 이게 전 세계적으로 거래되기 때문에 시가총액이 큰 비트코인 같은 종목들은 작전이 들어가기가 어렵거든요. 그런데 시가총액이 작은 종목. ◇ 정관용> 아까 말한 동전주 같은 거. ◆ 고란> 맞아요. 그리고 거래량이 적은 것들. 이거는 ‘펌핑방’이라고 부르거든요. 펌핑, 가격을 뛰어올린다라고 하는 펌핑방에서 무슨 무슨 호재가 있다라면서 일단 코인을 매수한 다음에 호재가 있다라고 일종의 지라시를 뿌리는 거예요, 여기저기 돌아다니면서. 그렇게 하고 나서 사람들이 가격이 오르기 시작하면 뭐지뭐지 하고 다른 개인투자자들이 뛰어드는 거죠. 그러면 고점에서 던집니다. ◇ 정관용> 그때 팔아내고. ◆ 고란> 그러면 개인투자자들은 고점에서 잡는 것이기 때문에 가격은 급락하고 손실이 커지게 되는 거죠. 그렇게 된 개인투자자를 시체라고 부르고 있고요. ◇ 정관용> 오늘 최종구 금융위원장이 가상통화 관련해서 기자간담회를 했습니다. 그동안에도 정부는 가상화폐 관련해서 여러 차례 무슨 대책들을 발표하기는 했는데 일각에서는 정부가 규제책을 내놓으면 오히려 가상화폐 인기가 올라간다 그런 얘기도 있잖아요. ◆ 고란> 왜냐하면 정부가 대책을 발표할 때마다 암호화폐, 가상화폐를 모르던 분들도 뭐지 이게. ◇ 정관용> 관심을 갖게 되고. ◆ 고란> 그러면서 이렇게 보다 보면 이렇게 돈을 많이 벌 수 있는 기회가 있단 말이야 하고 오히려 더 시장에 뛰어드는 거죠. 그런데 정부 규제가 어려운 이유가 이게 말씀드린 대로 글로벌 시장입니다. 국내에서 거래를 막아도 해외거래소로 코인을 보내면 거기서 거래할 수 있습니다. ◇ 정관용> 그러니까 오늘 최종구 위원장이 말한 것도 그냥 시중은행들 관리감독 좀 잘해라 그 정도잖아요. 그런데 그거 가지고 대책이 안 되는 거죠. ◆ 고란> 대책이 사실 정부 입장에서도 참 곤란할 것 같아요. 없던 시장이고 규제할 수도 없는 시장이고. ◇ 정관용> 올해를 전망하면 어떻습니까? 작년에는 아무튼 연초 대비 12월 달까지 수십 배 뛴 그런 상황이었는데 금년에 어떨까요? ◆ 고란> 제가 전망을 말씀드리는 게 맞는지 모르겠지만 저는 암호화폐 시장이 블록체인기술하고 연계돼 있기 때문에 소위 말하는 4차 산업혁명의 기본 기술이고요. 그렇기 때문에 시장 자체는 더 커질 거라고 보고 있고요. 그렇지만 시장 자체가 커지는 것과 내가 산 암호화폐가 오르는 것은 다른 문제거든요. 그래서 내가 산 암호화폐가 정말 기술력 있고 좋은 화폐라면 가격이 오를 테지만 그렇지 않다면 소위 말하는 상장폐지가 될 수도 있는 거고요. ◇ 정관용> 그렇죠. 아까 90년대 코스닥 버블 얘기했잖아요. 매일 상한가 한 달 이상. 그 결과는 어떻게 됐죠? ◆ 고란> 그 종목들 상장폐지됐죠. ◇ 정관용> 그렇죠? ◆ 고란> 그렇지만 그 코스닥 버블 가운데서도 살아남은 종목들이 미국에서는 아마존, 구글 이런 친구들이 살아남았고요. 국내에서는 네이버라는 기업이 탄생했고요. 이렇게 암호화폐 시장 열기가 지금은 투기에 가까울 정도로 크지만 이 투기 과정을 거치면서 옥석이 가려지면서 한국의 네이버, 미국의 구글 이런 게 암호화폐 시장에서도 나올 수 있다고 봅니다. ◇ 정관용> 나올 수도 있고 암호화폐, 가상화폐의 특징상 이거는 실물이 없는 거고 기업도 없는 거고 그렇잖아요. ◆ 고란> 중앙서버가 없는 거죠. ◇ 정관용> 뭔가 영업을 해서 이익을 내는 그런 게 없잖아요. ◆ 고란> 네. ◇ 정관용> 전체가 사라질 수도 있는 거 아닙니까, 논리적 가능성으로는. ◆ 고란> 전체가 사라지기는 어렵고요. 블록체인 기술은 살아남을 거라고 보고 있습니다. ◇ 정관용> 다시 말하면 지금은 너도 나도 끼어들고 있고 그러다 보니 가격은 계속 올라가고 있다. 이거는 부정할 수 없습니다. ◆ 고란> 맞습니다. ◇ 정관용> 다시 말하면 계속 올라가고 있다는 것은 어느 순간엔가 폭락할 수 있다는 거죠. 그 순간이 오늘일지 내일일지를 모른다는 거죠. ◆ 고란> 제가 이더리움이라는 암호화폐를 만든 비탈리 부테린을 지난해 인터뷰를 하면서 물어봤어요. 버블 맞냐 그랬더니 그 친구 하는 말이 버블 맞다. 그런데 이 버블이 언제 꺼질지 어디까지 갈지는 나도 모르겠다라는 얘기를 했더라고요. ◇ 정관용> 아무도 모릅니다. 그러나 꺼지는 건 분명합니다. ◆ 고란> 언제가 될지 모르는 거죠. ◇ 정관용> 꺼지는 것은 분명하죠. ◆ 고란> 버블은 꺼지는 거니까요. ◇ 정관용> 정치하시는 분들 거기에 귀기울이셨으면 좋겠습니다. 수고하셨습니다. ◆ 고란> 감사합니다. ◇ 정관용> 중앙일보 고란 기자였어요. [CBS 시사자키 홈페이지 바로 가기] [CBS <시사자키 정관용입니다>] woong@cbs.co.kr\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'- 암호화폐 시장은 블록체인 기술과 연계되어 4차 산업혁명의 기본 기술이라 더 커질 전망이다. - 하지만, 모든 암호화폐가 가격 상승을 보장하는 것은 아니고, 기술력 없는 암호화폐는 \"상장폐지\"될 수 있다.  - 과거 코스닥 버블과 같이 투기적인 시장 분위기에서도 실질적인 기업이나 기술이 살아남고 성장할 가능성은 있다. (예: 아마존, 구글, 네이버) - 현재 암호화폐 가격은 지속적으로 상승하고 있지만, 버블이 터질 때까지 언제까지 갈지는 알 수 없다.   '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "answer = gemma2.invoke(context+'기사 내용에서 주식 내용만 요약해주세요').content.replace('\\n', ' ').replace('*','').replace('#','') # 답변 저장\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'이 기사는 암호화폐 시장의 현재 상황과 미래 전망에 대해 논하고 있습니다. 고란 기자는 암호화폐 시장이 블록체인 기술과 연관되어 4차 산업혁명의 기본 기술로 자리매김할 것이라고 보고하며, 시장 자체가 커질 것이라고 전망합니다. 하지만 개별 암호화폐 가격 변동은 기술력 및 가치에 따라 달라질 수 있으며, 과열된 투기는 상장폐지 가능성을 초래할 수도 있다고 경고합니다.  과거 코스닥 버블 사례를 언급하며 투기적인 시장 분위기에서 진정한 가치를 지닌 기업이 부상하는 가능성을 제시합니다. 또한, 암호화폐의 실질적 가치 부재와 사업 모델의 미흡점을 지적하며 전체 시장이 사라질 수도 있다는 주장도 제시하지만 블록체인 기술 자체는 살아남을 것이라고 강조합니다.  최종적으로, 현재 암호화폐 가격 상승 추세가 버블 현상임을 인정하며 언젠가 폭락할 것은 분명하다는 점을 강조합니다.   '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "answer = gemma2.invoke(context+\"Please summarize the stock-related content in the article in Korean.\").content.replace('\\n', ' ').replace('*','').replace('#','') # 답변 저장\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 코스피 주식 시장, 하락 전환... 삼성전자 3%超 하락   코스피지수는 개인 매도와 외국인 매수세 둔화로 2거래일 만에 하락 전환, 전날 대비 0.12% 하락하며 2510.23 마감.  삼성전자는 지난해 4분기 실적이 시장기대치를 밑돌면서 3.11% 하락, 삼성전자우도 2.81% 하락.  SK하이닉스, 네이버 등 주요 종목도 하락세.    반면 현대차, POSCO, LG화학, KB금융, 삼성바이오로직스, 삼성물산, 삼성생명 등이 상승 마감.  개별 종목으로는 아남전자 가격제한폭까지 치솟으며, 이엔쓰리, SK케미칼, 평화산업 등도 주가 상승세 두드러짐.    '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "answer = gemma2.invoke(context1+'기사 내용에서 주식 내용만 요약해주세요').content.replace('\\n', ' ').replace('*','').replace('#','') # 답변 저장\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'코스피지수는 개인의 대규모 매도와 외국인 매수세 주춤으로 2거래일 만에 하락 전환, 0.12% 하락하여 장을 마감했습니다.  삼성전자(4분기 실적 미달)가 3% 이상 하락하며 주요 하락 원인이 되었습니다. 뉴욕증시는 반도체 및 기술주 상승세를 보이며 사상 최고치를 경신했지만, 국내 증시는 업종별 이슈에 따라 변동폭이 큰 모습을 보였습니다.  외국인은 7거래일 연속 매수세를 이어갔으나, 전날 대비 매수 규모가 줄었습니다. 기관의 순매수도 지속되었으며 금융투자, 연기금 등이 주목되는 편입니다. 반면 개인은 순매도했습니다. 전기전자 업종이 하락하였고 제조업, 비금속광물 등도 약세를 겪었습니다. 반대로 통신업이 상승했으며 철강금속, 유통업 등도 상승 마감했습니다.  시가총액 상위 종목은 엇갈린 모습을 보이며 삼성전자와 SK하이닉스 등이 하락한 반면 현대차, POSCO 등이 상승했습니다. 아남전자가 가격제한폭까지 치솟았으며 이엔쓰리, SK케미칼 등 주가 상승세가 두드러졌습니다. 신원, 세화아이엠씨 등은 큰 하락폭을 보였습니다.   '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "answer = gemma2.invoke(context1+\"Please summarize the stock-related content in the article in Korean.\").content.replace('\\n', ' ').replace('*','').replace('#','') # 답변 저장\n",
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gemma2 파인튜닝 (나중에 해봐야징..)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 개발 환경 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://devocean.sk.com/blog/techBoardDetail.do?ID=165703&boardType=techBlog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 필수 라이브러리 설치하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -q -U transformers==4.38.2\n",
    "!pip3 install -q -U datasets==2.18.0\n",
    "!pip3 install -q -U bitsandbytes==0.42.0\n",
    "!pip3 install -q -U peft==0.9.0\n",
    "!pip3 install -q -U trl==0.7.11\n",
    "!pip3 install -q -U accelerate==0.27.2\n",
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alpaco/anaconda3/envs/moon_mys/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import Dataset, load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline, TrainingArguments\n",
    "from peft import LoraConfig, PeftModel\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Huggingface 로그인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from huggingface_hub import notebook_login\n",
    "# notebook_login()\n",
    "\n",
    "from huggingface_hub import login\n",
    "\n",
    "# 토큰 입력\n",
    "token = \"your_hugging_face_token\"\n",
    "\n",
    "# Hugging Face 허브에 로그인\n",
    "login(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Dataset 생성 및 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 데이터셋 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"daekeun-ml/naver-news-summarization-ko\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 데이터셋 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 데이터셋 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Gemma 모델의 한국어 요약 테스트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 모델 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_MODEL = \"google/gemma-2b-it\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(BASE_MODEL, device_map={\"\":0})\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL, add_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Gemma-it의 프롬프트 형식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = dataset['train']['document'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"다음 글을 요약해주세요 :\\n\\n{}\".format(doc)\n",
    "    }\n",
    "]\n",
    "prompt = pipe.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Gemma-it 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = pipe(\n",
    "    prompt,\n",
    "    do_sample=True,\n",
    "    temperature=0.2,\n",
    "    top_k=50,\n",
    "    top_p=0.95,\n",
    "    add_special_tokens=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outputs[0][\"generated_text\"][len(prompt):])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Gemma 파인튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 주의: Colab GPU 메모리 한계로 이전장 추론에서 사용했던 메모리를 비워 줘야 파인튜닝을 진행 할 수 있습니다. <br> notebook 런타임 세션을 재시작 한 후 1번과 2번의 2.1 항목까지 다시 실행하여 로드 한 후 아래 과정을 진행합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 학습용 프롬프트 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(example):\n",
    "    prompt_list = []\n",
    "    for i in range(len(example['document'])):\n",
    "        prompt_list.append(r\"\"\"<bos><start_of_turn>user\n",
    "다음 글을 요약해주세요:\n",
    "\n",
    "{}<end_of_turn>\n",
    "<start_of_turn>model\n",
    "{}<end_of_turn><eos>\"\"\".format(example['document'][i], example['summary'][i]))\n",
    "    return prompt_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset['train']\n",
    "print(generate_prompt(train_data[:1])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 QLoRA 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=6,\n",
    "    target_modules=[\"q_proj\", \"o_proj\", \"k_proj\", \"v_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_MODEL = \"google/gemma-2b-it\"\n",
    "model = AutoModelForCausalLM.from_pretrained(BASE_MODEL, device_map=\"auto\", quantization_config=bnb_config)\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL, add_special_tokens=True)\n",
    "tokenizer.padding_side = 'right'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Trainer 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_data,\n",
    "    max_seq_length=512,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=\"outputs\",\n",
    "#        num_train_epochs = 1,\n",
    "        max_steps=3000,\n",
    "        per_device_train_batch_size=1,\n",
    "        gradient_accumulation_steps=4,\n",
    "        optim=\"paged_adamw_8bit\",\n",
    "        warmup_steps=0.03,\n",
    "        learning_rate=2e-4,\n",
    "        fp16=True,\n",
    "        logging_steps=100,\n",
    "        push_to_hub=False,\n",
    "        report_to='none',\n",
    "    ),\n",
    "    peft_config=lora_config,\n",
    "    formatting_func=generate_prompt,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4 Finetuned Model 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADAPTER_MODEL = \"lora_adapter\"\n",
    "\n",
    "trainer.model.save_pretrained(ADAPTER_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -alh lora_adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(BASE_MODEL, device_map='auto', torch_dtype=torch.float16)\n",
    "model = PeftModel.from_pretrained(model, ADAPTER_MODEL, device_map='auto', torch_dtype=torch.float16)\n",
    "\n",
    "model = model.merge_and_unload()\n",
    "model.save_pretrained('gemma-2b-it-sum-ko')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -alh ./gemma-2b-it-sum-ko"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Gemma 한국어 요약 모델 추론"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 주의: 마찬가지로 Colab GPU 메모리 한계로 학습 시 사용했던 메모리를 비워 줘야 파인튜닝을 진행 할 수 있습니다. <br> notebook 런타임 세션을 재시작 한 후 1번과 2번의 2.1 항목까지 다시 실행하여 로드 한 후 아래 과정을 진행합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Fine-tuned 모델 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_MODEL = \"google/gemma-2b-it\"\n",
    "FINETUNE_MODEL = \"./gemma-2b-it-sum-ko\"\n",
    "\n",
    "finetune_model = AutoModelForCausalLM.from_pretrained(FINETUNE_MODEL, device_map={\"\":0})\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL, add_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Fine-tuned 모델 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_finetuned = pipeline(\"text-generation\", model=finetune_model, tokenizer=tokenizer, max_new_tokens=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = dataset['test']['document'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"다음 글을 요약해주세요:\\n\\n{}\".format(doc)\n",
    "    }\n",
    "]\n",
    "prompt = pipe_finetuned.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = pipe_finetuned(\n",
    "    prompt,\n",
    "    do_sample=True,\n",
    "    temperature=0.2,\n",
    "    top_k=50,\n",
    "    top_p=0.95,\n",
    "    add_special_tokens=True\n",
    ")\n",
    "print(outputs[0][\"generated_text\"][len(prompt):])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain 파해치기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "편의상 import 한번에 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts import SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "model = ChatOllama(model= 'MoonYoungSik') # 여러가지 속성 값이 나옴.\n",
    "# model = OllamaLLM(model= 'MoonYoungSik') # 출력값이 답변만 나옴.\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOllama(model= 'EEVE-Korean-10.8B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"태양계에서 가장 큰 행성은 목성입니다. 태양으로부터 다섯 번째 행성으로, 지구보다 약 11배 더 크며 우리 태양계의 다른 모든 행성을 합친 것보다 무겁습니다. 목성의 주된 구성 성분은 가스이며 주로 수소와 헬륨으로 이루어져 있습니다. 거대한 규모와 강력한 자기장 때문에 '우주의 바다' 또는 '천왕성'으로도 불립니다.\", response_metadata={'model': 'MoonYoungSik', 'created_at': '2024-07-27T18:55:01.915520752Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 2142732630, 'load_duration': 12176726, 'prompt_eval_count': 32, 'prompt_eval_duration': 18389000, 'eval_count': 88, 'eval_duration': 1941718000}, id='run-79a4b1cd-69a7-40a4-a4e9-5065dd4f0a92-0')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke('태양계에서 가장 큰 행성은?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 출력 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = StrOutputParser() # 모델 출력의 content만 출력하게 해줌. 즉, .content와 같음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOllama(model= 'EEVE-Korean-10.8B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='반갑습니다! 저는 AI 어시스턴트입니다. 궁금한 점을 도와드리기 위해 여기 있습니다. 문영님, 무슨 도움이 필요하신가요? 새로운 것을 배우고 싶으신 건지, 정보를 찾고 계신 건지, 아니면 다른 이유가 있으신지요? 편하게 질문해 주시면 최선을 다해 도와드리겠습니다.', response_metadata={'model': 'EEVE-Korean-10.8B', 'created_at': '2024-07-25T07:14:04.327379858Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 1266927750, 'load_duration': 14675572, 'prompt_eval_count': 57, 'prompt_eval_duration': 49068000, 'eval_count': 63, 'eval_duration': 1069163000}, id='run-567b2347-a70d-4509-acca-dafc59866581-0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.invoke(\"안녕 내 이름은 문영식 입니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = model | output_parser #체인 기법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'안녕하세요! 문영님입니다. 궁금한 점이나 필요한 도움이 있으면 언제든 도와드리겠습니다. 편하게 물어보세요, 최선을 다해 유용하고 정확한 답변을 제공하도록 노력하겠습니다. 기억하세요, 존중과 안전이 최우선이며, 해로운 또는 비윤리적인 내용은 피해야 합니다. 제 답변의 정확성을 보장하기 위해 검증된 출처를 참조할 거라는 점도 알아두세요. 궁금한 점이나 어려운 부분이 있으면 언제든지 문의해 주시고, 함께 해결해 나가봅시다!'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chain.invoke(\"안녕 내 이름은 문영식 입니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'현재 날짜는 다음과 같습니다: 2021년 8월 5일입니다.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.invoke('오늘 날짜가 어떻게 되나요?').content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 프롬프트 템플릿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'안녕하세요, 제 이름은 문영식이고, 나이는 30살 입니다.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 템플릿 정의\n",
    "template_text = \"안녕하세요, 제 이름은 {name}이고, 나이는 {age}살 입니다.\"\n",
    "\n",
    "# PromptTemplate 인스턴스 생성\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "# 템플릿에 값 채워서 프롬프트 완성\n",
    "prompt_template.format(name=\"문영식\", age=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['age', 'name', 'national'], template='안녕하세요, 제 이름은 {name}이고, 나이는 {age}살 입니다.{national} 사람 입니다.를 {national}로 번역해주세요')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 템플릿 연결하기\n",
    "\n",
    "combined_prompt = (\n",
    "    prompt_template\n",
    "    + PromptTemplate.from_template(\"{national} 사람 입니다.\")\n",
    "    + \"를 {national}로 번역해주세요\"\n",
    ")\n",
    "\n",
    "combined_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'안녕하세요, 제 이름은 문영식이고, 나이는 30살 입니다.English 사람 입니다.를 English로 번역해주세요'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "combined_prompt.format(name='문영식', age=30, national='English')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, my name is Moon Young-Sik, and I am 30 years old. I am British.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chain = combined_prompt | model | output_parser\n",
    "chain.invoke({\"name\": \"문영식\", \"age\":30, \"national\":\"English\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 챗 프롬프트 템플릿 (from_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='이 시스템은 천문학 질문에 답변할 수 있습니다.'),\n",
       " HumanMessage(content='태양계에서 가장 큰 행성은 무엇인가요?')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 방법 1\n",
    "# 리스트 + 튜플 형태의 메시지 목록으로 프롬프트 생성 (type, content)\n",
    "chat_prompt1 = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"이 시스템은 천문학 질문에 답변할 수 있습니다.\"),\n",
    "        (\"user\", \"{user_input}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "messages = chat_prompt1.format_messages(user_input=\"태양계에서 가장 큰 행성은 무엇인가요?\")\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='이 시스템은 천문학에 답변할 수 있습니다.'),\n",
       " HumanMessage(content='태양계에서 가장 큰 행성은 무엇인가요?')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 방법 2\n",
    "chat_prompt2 = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessagePromptTemplate.from_template(\"이 시스템은 천문학에 답변할 수 있습니다.\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"{user_input}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "messages = chat_prompt2.format_messages(user_input=\"태양계에서 가장 큰 행성은 무엇인가요?\")\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain1 = chat_prompt1 | model | output_parser\n",
    "chain2 = chat_prompt2 | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'태양계에서 가장 큰 행성은 목성입니다. 목성은 거대한 가스로 이루어진 행성으로, 태양의 질량의 대략 318배에 달하며 현재 알려진 태양계 내 천체 중 가장 큰 질량을 가지고 있습니다. 이는 지구와 비교했을 때 약 317배 더 무겁습니다. 목성의 크기는 실제로 태양계의 다른 모든 행성들을 합친 것보다도 더 크기 때문에, 전체 태양계를 지배하는 거대한 행성으로 여겨지고 있습니다.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chain1.invoke({\"user_input\":\"태양계에서 가장 큰 행성은 무엇인가요?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"태양계에서 가장 큰 행성은 목성입니다. 이는 태양으로부터 두 번째로 먼 거리에 위치한 행성으로, 엄청난 크기와 질량 때문에 '목성'이라는 별명을 가지고 있습니다. 목성의 지름은 약 142,984킬로미터(88,846마일)이며, 수성에서 화성에 이르는 네 개 내행성의 질량을 모두 합친 것보다 무겁습니다. 목성은 주로 수소와 헬륨으로 이루어져 있으며, 회전하는 거대한 구름띠를 둘러싸고 있어 독특한 특징을 가지고 있습니다.\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chain2.invoke({\"user_input\":\"태양계에서 가장 큰 행성은 무엇인가요?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 챗 프롬프트 템플릿 (from_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = ChatPromptTemplate.from_template(\"단어 {input}을 최대한 짧게 설명해주세요.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain1 = prompt1 | model | StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'돈은 상품이나 서비스를 교환하거나 구매하기 위해 사용되는 매개체로 작용하는 가치의 척도입니다. 통화와 화폐 형태로 존재하며, 정부나 중앙은행에 의해 인정되고 지지됩니다. 돈은 거래와 상업 활동을 용이하게 하고 경제 성장을 촉진합니다.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chain1.invoke({\"input\" : \"돈\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 멀티 체인 기법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = ChatPromptTemplate.from_template(\"단어 {input}을 최대한 짧게 설명해주세요.\")\n",
    "prompt2 = ChatPromptTemplate.from_template(\"{input2}을 영어로 바꿔주세요\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain1 = prompt1 | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain2 = (\n",
    "    {\"input2\" : chain1} \n",
    "    | prompt2\n",
    "    | model\n",
    "    | output_parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Money,\" as a term, refers to a commodity that serves as a measure of value and a medium of exchange for trading goods and services. It is issued by governments or central banks and is usually referred to as legal tender or currency. Money can exist in physical form (cash) or digital form. Its primary purpose within an economy is to provide a means of storing value, serving as a unit of account, and acting as a medium of exchange.\n"
     ]
    }
   ],
   "source": [
    "print(chain2.invoke({\"input\":\"돈\"}))\n",
    "# print(chain2.invoke({\"input\":\"가정교육 없이 자란 사람과 가정교육을 받고 자란 사람은 행동과 정신에 얼마나 영향을 끼칠까요?\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 파라미터 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오픈AI 이렇게 한다는데 .. 올라마는 안되네..\n",
    "\n",
    "# params = {\n",
    "#     \"temperature\" : 0.2, # 0~1값인데 1에 가까울 수록 생성된 텍스트의 다양성이 커짐.\n",
    "#     \"max_tokens\" : 10, # 생성할 최대 토큰 수\n",
    "# }\n",
    "\n",
    "# kwargs = { #패널티 부분은 기본파라미터로 둘 수 없어서 기타로 뺌\n",
    "#     \"frequency_penalty\" : 0.5, # 이미 등장한 단어의 재등장 확률을 조정\n",
    "#     \"presence_penalty\" : 0.5, # 새로운 단어의 도입을 장려\n",
    "#     \"stop\" : [\"\\n\"] # 정지 시퀀스 설정\n",
    "# }\n",
    "\n",
    "# # 모델 인스턴스를 생성할 때 설정 함.\n",
    "# model = ChatOllama(model= 'EEVE-Korean-10.8B', **params, model_kwargs=kwargs)\n",
    "\n",
    "# question = \"태양계에서 가장 큰 행성은?\"\n",
    "\n",
    "# model.invoke(input = question).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "태양계에서 가장 큰 행성은 목성입니다. 목성은 가\n"
     ]
    }
   ],
   "source": [
    "# 일단 찾긴했는데 속도가 느림.\n",
    "# https://docs.llamaindex.ai/en/stable/api_reference/llms/ollama/\n",
    "# https://github.com/ollama/ollama/blob/main/docs/api.md\n",
    "# 위 경로에서 컨트롤F로 num_predict 치면 옵션들 나온다.\n",
    "\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.core import Settings\n",
    "\n",
    "# \"num_predict\": 10, 생성 토큰 수 설정\n",
    "model = Ollama(model=\"MoonYoungSik\", additional_kwargs={\"num_predict\": 15,}) #최대 토큰 수 설정.\n",
    "resp = model.complete(\"태양계에서 가장 큰 행성은 뭔가요?\")\n",
    "print(resp)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "num_keep: 모델이 이전의 생성된 토큰 중 얼마나 많은 토큰을 유지할지를 설정합니다. 이 값이 높을수록 이전의 생성된 결과를 더 많이 고려하게 됩니다.\n",
    "\n",
    "seed: 랜덤 시드 값으로, 모델의 결과를 재현 가능하게 하기 위해 사용됩니다. 같은 시드를 사용하면 같은 입력에 대해 항상 같은 출력을 얻을 수 있습니다.\n",
    "\n",
    "num_predict: 모델이 예측할 토큰의 수를 설정합니다. 이 값에 따라 생성되는 텍스트의 길이가 결정됩니다.\n",
    "\n",
    "top_k: 모델이 다음 단어를 예측할 때 고려할 상위 K개의 후보 단어를 제한합니다. 이 값이 낮을수록 더 결정적인 출력을 생성하지만, 다양성이 줄어들 수 있습니다.\n",
    "\n",
    "top_p: 누적 확률이 p 이하인 후보 단어만 고려합니다. 이 방법은 'nucleus sampling'이라고도 하며, 더 다양한 출력을 생성할 수 있습니다.\n",
    "\n",
    "min_p: 후보 단어의 최소 확률을 설정합니다. 이 값 이하의 확률을 가진 후보는 고려되지 않습니다.\n",
    "\n",
    "tfs_z: Top-k와 top-p의 조합인 TFS(Temperature Sampling)에서 온도 조절에 사용되는 값입니다. 더 높은 값은 더 많은 다양성을 허용합니다.\n",
    "\n",
    "typical_p: Typical Sampling에서 사용할 확률 값으로, 다음 단어의 예측을 보다 일반적인 것으로 제한합니다.\n",
    "\n",
    "repeat_last_n: 최근에 생성된 n개의 토큰을 기억하여, 이와 같은 토큰이 반복되지 않도록 제어합니다.\n",
    "\n",
    "temperature: 샘플링의 온도를 조절하여 생성된 텍스트의 다양성을 조절합니다. 낮은 값은 더 결정적인 결과를, 높은 값은 더 다양한 결과를 생성합니다.\n",
    "\n",
    "repeat_penalty: 반복된 단어에 대한 페널티를 설정하여, 같은 단어가 반복되었을 때 그 단어의 확률을 감소시킵니다.\n",
    "\n",
    "presence_penalty: 이미 생성된 단어의 출현을 억제하여, 새로운 단어가 등장하도록 유도합니다.\n",
    "\n",
    "frequency_penalty: 이미 자주 등장한 단어에 대한 페널티를 부여하여, 그 단어의 반복 출현을 줄입니다.\n",
    "\n",
    "mirostat: Mirostat 샘플링을 사용할지 여부를 결정하는 옵션입니다. 이 방법은 생성된 텍스트의 품질을 조절하는 데 도움을 줍니다.\n",
    "\n",
    "mirostat_tau: Mirostat 알고리즘의 tau 매개변수로, 생성되는 텍스트의 품질을 조절하는 데 사용됩니다.\n",
    "\n",
    "mirostat_eta: Mirostat 알고리즘의 eta 매개변수로, 텍스트 생성의 다양성을 조절합니다.\n",
    "\n",
    "penalize_newline: 생성된 텍스트에 줄바꿈을 억제하는 옵션입니다. 줄바꿈이 자주 발생하는 것을 방지하려면 true로 설정합니다.\n",
    "\n",
    "stop: 텍스트 생성을 중지할 특정 문자열을 설정합니다. 예를 들어, \"\\n\"이나 \"user:\"는 생성 중지 조건이 됩니다.\n",
    "\n",
    "numa: NUMA(비균일 메모리 액세스) 시스템에서 메모리 사용을 최적화할지 여부를 결정합니다.\n",
    "\n",
    "num_ctx: 입력이나 출력을 위한 문맥의 최대 길이를 설정합니다. 이 값에 따라 모델이 한 번에 처리할 수 있는 토큰 수가 결정됩니다.\n",
    "\n",
    "num_batch: 한 번에 처리할 배치의 수를 설정합니다. 이 값이 높을수록 더 많은 입력을 동시에 처리할 수 있습니다.\n",
    "\n",
    "num_gpu: 사용하려는 GPU의 수를 지정합니다. 여러 GPU를 사용할 수 있습니다.\n",
    "\n",
    "main_gpu: 주 GPU의 인덱스를 설정하여, 모델의 주요 연산을 수행할 GPU를 지정합니다.\n",
    "\n",
    "low_vram: VRAM 사용을 최적화할지 여부를 결정합니다. VRAM 사용이 적은 환경에서 모델을 실행할 때 유용합니다.\n",
    "\n",
    "f16_kv: 16비트 부동 소수점으로 키-값 저장소를 사용하는 옵션입니다. 메모리 사용을 줄이고 성능을 향상시키는 데 도움을 줍니다.\n",
    "\n",
    "vocab_only: 단어 사전만 사용할지 여부를 결정합니다. 이 옵션을 true로 설정하면 사전만 로드합니다.\n",
    "\n",
    "use_mmap: 메모리 맵 파일을 사용할지 여부를 결정합니다. 이 옵션을 사용하면 큰 파일을 더 효율적으로 읽을 수 있습니다.\n",
    "\n",
    "use_mlock: 메모리 잠금을 사용할지 여부입니다. 이 옵션을 활성화하면 프로세스의 메모리를 잠가서 페이지 아웃되지 않도록 보장합니다.\n",
    "\n",
    "num_thread: 사용할 스레드의 수를 설정합니다. 이 값이 높을수록 병렬 처리 성능이 향상됩니다.\n",
    "\n",
    "이 모든 옵션은 모델의 동작 방식과 성능에 영향을 미치므로 필요에 따라 조정할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q langchain tiktoken chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.2.9'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import langchain\n",
    "langchain.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "순서 : \n",
    "\n",
    "데이터 읽어오기 -> 데이터를 작은 단위(chunk)로 분리 -> 분리된 데이터를 벡터스토어에 저장 -> 검색 -> 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "13153\n",
      "좀 더 빠르게 강력한 수단을 이용해야 합니다. 특히 정책 문서에 명시된 원칙을 지키지 않는 것은 대부분의 경우 다른 사용자에게 받아들여지지 않습니다 (다른 분들에게 예외 상황임을 설득할 수 있다면 가능하기는 하지만요). 이는 당신을 포함해서 편집자 개개인이 정책과 지침을 직접 집행 및 적용한다는 것을 의미합니다.\n",
      "특정 사용자가 명백히 정책에 반하는 행동을 하거나 정책과 상충되는 방식으로 지침을 어기는 경우, 특히 의도적이고 지속적으로 그런 행위를 하는 경우 해당 사용자는 관리자의 제재 조치로 일시적, 혹은 영구적으로 편집이 차단될 수 있습니다. 영어판을 비롯한 타 언어판에서는 일반적인 분쟁 해결 절차로 끝낼 수 없는 사안은 중재위원회가 개입하기도 합니다.\n",
      "\n",
      "문서 내용\n",
      "정책과 지침의 문서 내용은 처음 읽는 사용자라도 원칙과 규범을 잘 이해할 수 있도록 다음 원칙을 지켜야 합니다.\n",
      "\n",
      "명확하게 작성하세요. 소수만 알아듣거나 준법률적인 단어, 혹은 지나치게 단순한 표현은 피해야 합니다. 명확하고, 직접적이고, 모호하지 않고, 구체적으로 작성하세요. 지나치게 상투적인 표현이나 일반론은 피하세요. 지침, 도움말 문서 및 기타 정보문 문서에서도 \"해야 합니다\" 혹은 \"하지 말아야 합니다\" 같이 직접적인 표현을 굳이 꺼릴 필요는 없습니다.\n",
      "가능한 간결하게, 너무 단순하지는 않게. 정책이 중언부언하면 오해를 부릅니다. 불필요한 말은 생략하세요. 직접적이고 간결한 설명이 마구잡이식 예시 나열보다 더 이해하기 쉽습니다. 각주나 관련 문서 링크를 이용하여 더 상세히 설명할 수도 있습니다.\n",
      "규칙을 만든 의도를 강조하세요. 사용자들이 상식대로 행동하리라 기대하세요. 정책의 의도가 명료하다면, 추가 설명은 필요 없죠. 즉 규칙을 '어떻게' 지키는지와 더불어 '왜' 지켜야 하는지 확실하게 밝혀야 합니다.\n",
      "범위는 분명히, 중복은 피하기. 되도록 앞부분에서 정책 및 지침의 목적과 범위를 분명하게 밝혀야 합니다. 독자 대부분은 도입부 초반만 읽고 나가버리니까요. 각 정책 문서의 내용은 해당 정\n"
     ]
    }
   ],
   "source": [
    "# Data Loader - 웹페이지 데이터 가져오기\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "\"\"\"\n",
    "langchain_community.document_loaders 모듈에서 WebBaseLoader 클래스를 사용하여 웹페이지 데이터를 가져오는 방법을 보여줍니다.\n",
    "웹 크롤링을 통해 웹페이지의 텍스트 데이터를 추출하여 Document 객체의 리스트로 변환합니다.\n",
    "\"\"\"\n",
    "\n",
    "# 위키피디아 정책과 지침\n",
    "url = 'https://ko.wikipedia.org/wiki/%EC%9C%84%ED%82%A4%EB%B0%B1%EA%B3%BC:%EC%A0%95%EC%B1%85%EA%B3%BC_%EC%A7%80%EC%B9%A8'\n",
    "loader = WebBaseLoader(url)\n",
    "\n",
    "# 웹페이지 텍스트 -> Documents\n",
    "docs = loader.load()\n",
    "print(len(docs)) # 1\n",
    "print(len(docs[0].page_content)) #13153 글자\n",
    "print(docs[0].page_content[5000:6000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "page_content='제안과 채택\n",
      " 백:아님 § 관료주의  문서를 참고하십시오. 단축백:제안\n",
      "제안 문서란 정책과 지침으로 채택하자고 의견을 묻는 문서이나 아직 위키백과 내에 받아들여지는 원칙으로 확립되지는 않은 문서입니다. {{제안}} 틀을 붙여 공동체 내에서 정책이나 지침으로 채택할 지 의견을 물을 수 있습니다. 제안 문서는 정책과 지침이 아니므로 아무리 실제 있는 정책이나 지침을 요약하거나 인용해서 다른 문서에 쓴다고 해도 함부로 정책이나 지침 틀을 붙여서는 안 됩니다.\n",
      "'제안'은 완전 새로운 원칙이라기보다, 기존의 불문율이나 토론 총의의 문서를 통한 구체화에 가깝습니다. 많은 사람들이 쉽게 제안을 받아들이도록 하기 위해서는, 기초적인 원칙을 우선 정하고 기본 틀을 짜야 합니다. 정책과 지침의 기본 원칙은 \"왜 지켜야 하는가?\", \"어떻게 지켜야 하는가?\" 두 가지입니다. 특정 원칙을 정책이나 지침으로 확립하기 위해서는 우선 저 두 가지 물음에 성실하게 답하는 제안 문서를 작성해야 합니다.\n",
      "좋은 아이디어를 싣기 위해 사랑방이나 관련 위키프로젝트에 도움을 구해 피드백을 요청할 수 있습니다. 이 과정에서 공동체가 어느 정도 받아들일 수 있는 원칙이 구체화됩니다. 많은 이와의 토론을 통해 공감대가 형성되고 제안을 개선할 수 있습니다.\n",
      "정책이나 지침은 위키백과 내의 모든 편집자들에게 적용되는 원칙이므로 높은 수준의 총의가 요구됩니다. 제안 문서가 잘 짜여졌고 충분히 논의되었다면, 더 많은 공동체의 편집자와 논의를 하기 위해 승격 제안을 올려야 합니다. 제안 문서 맨 위에 {{제안}}을 붙여 제안 안건임을 알려주고, 토론 문서에 {{의견 요청}}을 붙인 뒤 채택 제안에 관한 토론 문단을 새로 만들면 됩니다. 많은 편집자들에게 알리기 위해 관련 내용을 {{위키백과 소식}}에 올리고 사랑방에 이를 공지해야 하며, 합의가 있을 경우 미디어위키의 sitenotice(위키백과 최상단에 노출되는 구역)에 공지할 수도 있습니다.' metadata={'source': 'https://ko.wikipedia.org/wiki/%EC%9C%84%ED%82%A4%EB%B0%B1%EA%B3%BC:%EC%A0%95%EC%B1%85%EA%B3%BC_%EC%A7%80%EC%B9%A8', 'title': '위키백과:정책과 지침 - 위키백과, 우리 모두의 백과사전', 'language': 'ko'}\n"
     ]
    }
   ],
   "source": [
    "# Text Split (Documents -> small chunks: Documents)\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\"\"\"\n",
    "RecursiveCharacterTextSplitter라는 텍스트 분할 도구를 사용합니다.\n",
    "13153 개의 문자로 이루어진 긴 문장을 최대 1000글자 단위로 분할하는 것입니다.\n",
    "200글자는 각 분할마다 겹치게 하여 문맥이 잘려나가지 않고 유지되게 합니다. \n",
    "실행 결과를 보면 18개 조각으로 나눠지게 됩니다.\n",
    "LLM 모델이나 API의 입력 크기에 대한 제한이 있기 때문에, 제한에 걸리지 않도록 적정한 크기로 텍스트의 길이를 줄일 필요가 있습니다. \n",
    "그리고, 프롬프트가 지나치게 길어질 경우 중요한 정보가 상대적으로 희석되는 문제가 있을 수도 있습니다.\n",
    "따라서, 적정한 크기로 텍스트를 분할하는 과정이 필요합니다.\n",
    "\"\"\"\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "print(len(splits)) # 18개의 조각으로 나뉨\n",
    "print(splits[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'제안과 채택\\n\\xa0백:아님 §\\xa0관료주의  문서를 참고하십시오. 단축백:제안\\n제안 문서란 정책과 지침으로 채택하자고 의견을 묻는 문서이나 아직 위키백과 내에 받아들여지는 원칙으로 확립되지는 않은 문서입니다. {{제안}} 틀을 붙여 공동체 내에서 정책이나 지침으로 채택할 지 의견을 물을 수 있습니다. 제안 문서는 정책과 지침이 아니므로 아무리 실제 있는 정책이나 지침을 요약하거나 인용해서 다른 문서에 쓴다고 해도 함부로 정책이나 지침 틀을 붙여서는 안 됩니다.\\n\\'제안\\'은 완전 새로운 원칙이라기보다, 기존의 불문율이나 토론 총의의 문서를 통한 구체화에 가깝습니다. 많은 사람들이 쉽게 제안을 받아들이도록 하기 위해서는, 기초적인 원칙을 우선 정하고 기본 틀을 짜야 합니다. 정책과 지침의 기본 원칙은 \"왜 지켜야 하는가?\", \"어떻게 지켜야 하는가?\" 두 가지입니다. 특정 원칙을 정책이나 지침으로 확립하기 위해서는 우선 저 두 가지 물음에 성실하게 답하는 제안 문서를 작성해야 합니다.\\n좋은 아이디어를 싣기 위해 사랑방이나 관련 위키프로젝트에 도움을 구해 피드백을 요청할 수 있습니다. 이 과정에서 공동체가 어느 정도 받아들일 수 있는 원칙이 구체화됩니다. 많은 이와의 토론을 통해 공감대가 형성되고 제안을 개선할 수 있습니다.\\n정책이나 지침은 위키백과 내의 모든 편집자들에게 적용되는 원칙이므로 높은 수준의 총의가 요구됩니다. 제안 문서가 잘 짜여졌고 충분히 논의되었다면, 더 많은 공동체의 편집자와 논의를 하기 위해 승격 제안을 올려야 합니다. 제안 문서 맨 위에 {{제안}}을 붙여 제안 안건임을 알려주고, 토론 문서에 {{의견 요청}}을 붙인 뒤 채택 제안에 관한 토론 문단을 새로 만들면 됩니다. 많은 편집자들에게 알리기 위해 관련 내용을 {{위키백과 소식}}에 올리고 사랑방에 이를 공지해야 하며, 합의가 있을 경우 미디어위키의 sitenotice(위키백과 최상단에 노출되는 구역)에 공지할 수도 있습니다.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# page_content 속성\n",
    "splits[10].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'https://ko.wikipedia.org/wiki/%EC%9C%84%ED%82%A4%EB%B0%B1%EA%B3%BC:%EC%A0%95%EC%B1%85%EA%B3%BC_%EC%A7%80%EC%B9%A8',\n",
       " 'title': '위키백과:정책과 지침 - 위키백과, 우리 모두의 백과사전',\n",
       " 'language': 'ko'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# metadata 속성\n",
    "splits[10].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 내용 담기\n",
    "wikidoc =[]\n",
    "for i in range(len(splits)):\n",
    "    wikidoc.append(splits[i].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임베딩 모델 다운로드\n",
    "!ollama pull mxbai-embed-large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db 다운로드\n",
    "!pip install ollama chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding': [-1.2404356002807617, 0.11540883779525757, -0.5825051069259644, 0.7868903875350952, 0.031510114669799805, -0.6319732069969177, 0.5164114832878113, 0.45837607979774475, 0.5429878234863281, 0.5246871113777161, 0.7976201176643372, -0.260843425989151, 0.6530691385269165, -0.33664533495903015, -0.8372882008552551, -0.46633636951446533, 0.028428150340914726, -0.47399988770484924, -0.5276591777801514, 0.21041655540466309, -0.5878123044967651, -0.36867737770080566, -1.5862038135528564, -0.10867688059806824, -0.6086388230323792, 1.3152672052383423, 0.2227800488471985, 0.06816345453262329, 0.9426928758621216, 0.6081036329269409, -0.2452099323272705, -0.3478848934173584, -0.4580736458301544, -0.568959653377533, 0.002670612186193466, 0.12101763486862183, 1.0061044692993164, -0.861430823802948, -0.12036222219467163, -0.048622578382492065, -0.4003521203994751, -0.43645569682121277, 0.18562152981758118, -1.3357632160186768, -0.6030087471008301, -0.6336873173713684, 0.07397031784057617, -0.6463910341262817, 0.670712947845459, -0.4075358510017395, 0.2548593282699585, 0.44412869215011597, 1.0418517589569092, -0.39190027117729187, -0.129220113158226, -0.18305715918540955, -0.6218330264091492, -0.17499998211860657, -0.7771060466766357, 0.021774303168058395, 0.4385150372982025, 0.5596252679824829, 0.8008359670639038, -0.6115813851356506, -0.28422385454177856, 0.42951080203056335, 0.03675378859043121, 0.14766475558280945, 0.24495211243629456, -0.42025747895240784, -0.6426995396614075, 0.7038578391075134, -0.6406046748161316, -0.39922040700912476, -0.3069280683994293, 0.17592473328113556, -0.6247871518135071, 0.2079489529132843, -0.27620914578437805, 0.38527819514274597, 0.4620133340358734, 0.37836116552352905, 0.4551902413368225, -0.3258047103881836, -0.3880060911178589, 0.05703352391719818, 0.12469227612018585, -0.1146092489361763, 0.11288373917341232, -0.15663228929042816, -0.19316333532333374, 0.9564228653907776, -0.279833048582077, -0.520073652267456, -0.20583507418632507, 0.7742488384246826, -0.314595103263855, 0.16275593638420105, -1.1860870122909546, 0.6373441219329834, 0.3308732211589813, 0.7333388328552246, -0.9013631343841553, 1.1465051174163818, -0.5512774586677551, -0.06171184778213501, 0.14592590928077698, -0.34113314747810364, -0.3487843871116638, -0.8802016973495483, 0.006709851324558258, -0.29199904203414917, 0.02399355173110962, -0.11378121376037598, -0.5581200122833252, 1.0219225883483887, -0.12994229793548584, 0.37210384011268616, 0.2780821919441223, -0.415086030960083, -0.049324095249176025, 0.1793244332075119, 0.3881100118160248, -0.20732122659683228, -0.15124469995498657, -0.8405135869979858, 0.7211020588874817, 1.1595838069915771, -0.5462740063667297, -0.5321362614631653, -0.20960935950279236, 0.2556003928184509, 0.5673292875289917, 0.03268977999687195, 0.7712759971618652, 0.7140272259712219, -0.00039324164390563965, -0.13078004121780396, 0.9324378967285156, -0.6783884763717651, 0.2589963376522064, 0.5832180976867676, -0.1466609090566635, 1.744593620300293, 0.32120969891548157, 0.5470449924468994, 0.2855565547943115, 0.18389102816581726, -0.4649420976638794, -0.29526278376579285, -0.7369990944862366, 0.22548435628414154, 0.07077811658382416, 0.23925800621509552, 0.31011661887168884, 0.22983914613723755, -0.11276338249444962, 0.10989828407764435, -0.4069128632545471, 0.038765162229537964, 0.49079570174217224, 0.9471835494041443, -0.09315880388021469, 0.3353455662727356, -0.43676817417144775, 0.6329505443572998, -0.8875424265861511, -0.7542552947998047, -0.07254798710346222, -0.8641456365585327, 0.49473586678504944, 1.0061923265457153, -0.6837866306304932, -0.4188429117202759, 0.16662684082984924, 0.2744586765766144, 0.3202502727508545, 0.25626325607299805, 0.606067419052124, 0.14228035509586334, -0.18880373239517212, -0.25447022914886475, 0.5796959400177002, 1.376482367515564, 0.39154350757598877, 0.34161245822906494, -0.12472753971815109, 0.0004252614453434944, -0.45063021779060364, -0.4497709274291992, 0.4651150107383728, 0.4509848356246948, -0.2815499007701874, 0.4239291846752167, -0.5274085402488708, 0.05219270661473274, -0.47082212567329407, -0.702366828918457, 0.0831620991230011, -1.6494005918502808, -0.5750975608825684, 0.5312111973762512, -0.2285599261522293, -0.16270223259925842, 0.18578889966011047, -1.1869007349014282, -0.09817689657211304, 0.7699772119522095, -0.8396551609039307, -0.03248600661754608, 0.6580899953842163, 0.7813122868537903, -0.8042811751365662, -0.5453243851661682, 1.1283687353134155, -0.7060919404029846, -0.3680846393108368, 1.0594838857650757, 0.04629981517791748, 0.4021575152873993, 0.11356295645236969, 1.0102099180221558, 0.22006680071353912, 0.88238924741745, -0.3531421720981598, 0.7537269592285156, -0.07833261042833328, 1.080039143562317, -0.3570294678211212, -0.09119588136672974, 0.3869800865650177, 0.47614383697509766, 0.03317052125930786, 1.0669753551483154, 0.8911158442497253, 0.2022201269865036, 0.7433834075927734, 1.039099931716919, 0.5666894316673279, 0.06557103991508484, 0.20959800481796265, 0.3787829279899597, 1.1737698316574097, 0.880698561668396, -0.052620500326156616, 0.22997872531414032, 0.568672776222229, -0.0004766881465911865, -0.6002988815307617, -0.26731738448143005, 0.4015882909297943, 1.2693684101104736, 1.6634726524353027, 0.8422752022743225, -0.8566840887069702, -0.7291061878204346, 1.1416330337524414, 0.6948976516723633, -0.7835836410522461, -0.36932051181793213, 0.42151620984077454, 0.9575290083885193, -0.16655172407627106, -0.026049982756376266, -0.18140347301959991, 0.35094448924064636, -0.29687902331352234, -0.42473921179771423, -0.4744332730770111, -0.3850725293159485, -0.9822244048118591, 0.20180608332157135, -0.7913472652435303, -0.49579674005508423, -1.1361929178237915, -0.1797553151845932, 0.714563250541687, -0.45027777552604675, 1.3764408826828003, 0.4477118253707886, -0.12876485288143158, 0.3105035424232483, -0.41659143567085266, 0.6168197393417358, -0.13619893789291382, 0.693084180355072, 0.09359905868768692, 0.5574460029602051, -0.4811985492706299, 0.9995306730270386, -1.1060731410980225, 0.8529650568962097, 0.42872294783592224, -0.023770783096551895, 0.09213599562644958, -0.16891685128211975, 0.03352678567171097, -0.052358560264110565, -0.32789480686187744, -0.4636141061782837, -0.5037034749984741, -0.18879225850105286, -0.7372156977653503, -0.5710335373878479, -0.6412930488586426, 0.9703904390335083, 0.1746712028980255, 0.08676955103874207, 0.842909038066864, 1.4084306955337524, -0.3693523705005646, 0.6879422068595886, -0.08585076034069061, -0.050057075917720795, -1.0933260917663574, 1.2146499156951904, 0.39331430196762085, 0.6028623580932617, -0.43995898962020874, -0.39564502239227295, -0.503621518611908, 0.4050339460372925, -0.5566917657852173, -0.3593195378780365, 0.4760265648365021, -0.24541990458965302, 0.3580249845981598, -1.2360758781433105, 0.4497065842151642, -1.2368106842041016, 0.17148025333881378, -1.1637043952941895, -0.47103574872016907, 1.1213923692703247, 0.4029476046562195, 0.05595441907644272, 0.5330697298049927, -0.36328232288360596, -0.4619172215461731, -0.16560782492160797, 0.8911790251731873, -0.45923465490341187, -0.2990376949310303, 1.175087809562683, -0.47032949328422546, 0.4866849482059479, 0.07943443953990936, -0.1194622591137886, -0.4076686203479767, -0.38261809945106506, -0.7167240977287292, -0.3100767433643341, 0.6680471301078796, -0.33572909235954285, -0.4160255789756775, 0.9066165089607239, -1.1097846031188965, -0.9435115456581116, 0.2099413275718689, 0.5317724943161011, 1.1329376697540283, 0.0846700668334961, 0.9954656362533569, -0.6106163263320923, 0.14634576439857483, -1.2123463153839111, 0.7085400819778442, 0.0340350866317749, 0.5920983552932739, -1.4268958568572998, 0.27300238609313965, -0.2847849726676941, -0.41672655940055847, 0.13923580944538116, -0.4849894642829895, -0.7759564518928528, 0.7761433720588684, -0.36942043900489807, 0.3669869601726532, -0.6199101209640503, 0.5706093311309814, -0.8800365328788757, 0.032750941812992096, 1.088924765586853, 0.025168385356664658, 0.834547221660614, -0.34513548016548157, 0.029647350311279297, 0.22719331085681915, -0.9476718902587891, 0.33599960803985596, -0.8228356838226318, -0.043545447289943695, -0.08441083133220673, -0.7121052145957947, -1.1876606941223145, 0.8083074688911438, -0.052556104958057404, 0.6629975438117981, 0.38535982370376587, 0.5119718313217163, 0.0964234471321106, 0.6170344948768616, 0.13119064271450043, -0.5172807574272156, -0.0050674378871917725, -0.5378643274307251, 0.43778303265571594, 0.5776342749595642, 0.5120062232017517, -1.6481139659881592, -0.4901292026042938, -0.9892004728317261, 0.03903082385659218, 0.7589409351348877, 0.035673148930072784, -0.20153942704200745, 0.0966000109910965, 0.24446344375610352, 0.4012814164161682, -0.14648815989494324, -0.46388283371925354, -0.1340152621269226, 0.8889581561088562, 0.7917978167533875, -0.6296851634979248, 0.6400486826896667, -0.5562393665313721, 0.6642096042633057, 1.0415054559707642, -0.13170194625854492, -0.5158064365386963, 0.015787921845912933, 0.1404939591884613, -0.9651607871055603, 0.2006380409002304, 0.6624495387077332, -0.21324798464775085, 0.1705705225467682, -0.9670206904411316, 0.1220807433128357, -0.14251917600631714, -1.0260735750198364, -0.8954213857650757, -0.20923607051372528, -0.4818970561027527, 0.3589394688606262, 1.0204167366027832, -0.45739424228668213, -0.6606813669204712, 0.9145159125328064, -0.4631805419921875, 1.25548255443573, -0.9983168840408325, -0.19329774379730225, 0.07750280201435089, 0.2120225578546524, 0.07462795078754425, 1.0382884740829468, -0.6345785856246948, 0.07092273980379105, 0.15096841752529144, 0.08169399946928024, -0.2842070162296295, -0.30316194891929626, 0.6185426712036133, 0.050664179027080536, -0.27260497212409973, 0.05990740656852722, 0.15228532254695892, -0.9700722694396973, 0.4345684349536896, -0.15971805155277252, 0.3180367052555084, 0.6080256700515747, -0.8456409573554993, 0.7017161846160889, 0.3234497308731079, -0.49781566858291626, 0.10918749868869781, -0.4690096974372864, 0.26627159118652344, 0.12231723964214325, -1.2268162965774536, -0.6353771686553955, -1.05271315574646, 0.033021241426467896, 0.6292734742164612, -0.00842379406094551, 0.6977190375328064, -0.1807851493358612, 0.19769324362277985, 0.10038739442825317, -0.8412438631057739, 0.223798006772995, -0.2270406186580658, -0.350320041179657, -0.3805651068687439, 0.5305991172790527, 0.27799445390701294, 0.6958484649658203, -1.0043410062789917, -1.2312061786651611, 0.156471386551857, 0.05705252289772034, 0.22361432015895844, -1.3598852157592773, -0.1641741544008255, 0.2051611989736557, -0.35065802931785583, -0.5297778248786926, 0.47738486528396606, -0.4154086709022522, 0.09371587634086609, 0.3044676184654236, 0.5611222386360168, 0.03880850970745087, -0.30167925357818604, -1.2436612844467163, 0.9821072816848755, 0.16949576139450073, -1.2042585611343384, -0.937916100025177, 0.7111430764198303, -0.013948529958724976, 1.21054208278656, 0.09144288301467896, -0.33254343271255493, -0.37014585733413696, -0.6440841555595398, -0.20905016362667084, -1.014994502067566, -0.4789542555809021, -0.8985166549682617, -0.5856112837791443, -0.831340491771698, 0.5765720009803772, -0.055181875824928284, -0.17976896464824677, -0.7695175409317017, -0.26593053340911865, 0.03229071944952011, -0.3089478611946106, 0.24123427271842957, -0.1220116838812828, -0.13889704644680023, 0.18771766126155853, 1.3741140365600586, 0.2706156373023987, 0.7090310454368591, 0.46591275930404663, -0.22806774079799652, -0.024325279518961906, 0.8740895390510559, -1.1404818296432495, -0.44031304121017456, 0.003137141466140747, 0.3351905047893524, 0.5041781663894653, -0.1695513129234314, -0.49939608573913574, 0.7292382121086121, -0.7443695068359375, 0.1376592516899109, 0.4644956588745117, 0.13935087621212006, -0.36990922689437866, -0.5155562162399292, 0.7058751583099365, -0.7555262446403503, -0.05674177408218384, -0.1442873626947403, 1.4633548259735107, 0.10738730430603027, 0.8431032299995422, -0.93827223777771, -0.9039905071258545, -1.4930222034454346, -0.39240193367004395, 0.2171299159526825, -0.02065116912126541, -0.6153493523597717, -0.23405852913856506, 0.2930614948272705, 0.6903297305107117, -0.04690445959568024, 0.36169949173927307, 1.947121262550354, 0.3111962080001831, -0.28560352325439453, -0.8912810683250427, 0.3556200861930847, 0.5989207029342651, -0.7571933269500732, -0.24133233726024628, -0.3202715516090393, -1.3599565029144287, -0.17091786861419678, -0.6544234752655029, -1.2253273725509644, -0.96124267578125, -0.8384756445884705, 1.0071314573287964, -0.25181689858436584, 0.7806938886642456, -0.5255787968635559, -0.971949577331543, -0.8427488803863525, 1.0885369777679443, 0.5292280316352844, -0.12862884998321533, 0.9818216562271118, 0.4054713249206543, 0.6975193023681641, 0.6986609697341919, -0.26367008686065674, 0.4323297441005707, -0.5238015055656433, 1.1219608783721924, 0.09739772975444794, -0.41203463077545166, 0.5038472414016724, 0.7699642181396484, -0.8753516674041748, -0.5603369474411011, 0.12750348448753357, -0.3573237955570221, -0.31854045391082764, -1.1500312089920044, -0.07223503291606903, -0.19265995919704437, 0.4652519226074219, 0.016930323094129562, 0.3918515145778656, 0.940422773361206, -0.8547297716140747, 0.19698132574558258, -0.1928403526544571, -0.20827901363372803, 0.3851049542427063, 0.9743289947509766, -0.06643947958946228, 0.2740315794944763, -1.532286524772644, -0.5763161182403564, -0.7238110899925232, -0.293967068195343, 1.0755672454833984, 0.21605175733566284, 0.607213020324707, 1.0921072959899902, 0.365029513835907, 1.1083189249038696, -0.1889336258172989, 0.45673897862434387, 0.6649606823921204, -0.5118263959884644, -1.3044909238815308, -0.19821690022945404, 0.4587160050868988, -0.3867334723472595, -0.024902965873479843, -0.9477429389953613, 0.2205624282360077, 0.01836918294429779, 0.006425879895687103, -0.6370042562484741, -0.30330944061279297, -0.16110818088054657, -1.4416815042495728, -0.37201330065727234, -0.044172175228595734, 0.15311861038208008, -0.6194975972175598, 0.40761780738830566, 0.4288902282714844, -0.21480511128902435, -0.4679100513458252, 0.37219297885894775, -0.18928739428520203, 0.44785740971565247, -0.3168189227581024, 0.35452911257743835, -1.3977971076965332, -0.5999209880828857, -1.2561482191085815, 0.32776835560798645, -0.030944257974624634, 0.13089077174663544, -0.03960218280553818, 0.39447617530822754, -1.0440964698791504, 0.5797426700592041, -0.24024587869644165, -0.07223989069461823, -0.30271977186203003, -0.20374950766563416, 0.2087772935628891, 0.1660759001970291, 0.3088524341583252, 0.5548979043960571, 1.3283032178878784, 0.221063494682312, 0.220125213265419, -0.5031043887138367, -0.2771112620830536, -0.4199254512786865, -0.4341185986995697, 0.7283011078834534, 0.20605289936065674, -0.7139323949813843, -0.3894202411174774, 0.2369861900806427, -0.3237570822238922, -0.23265333473682404, 0.10688094049692154, 0.1489230841398239, -0.1731267124414444, -0.6761505007743835, -0.03648069500923157, 0.9440635442733765, -0.04966379702091217, -0.3663000762462616, -0.44628822803497314, 0.5214312672615051, 0.01482979953289032, -0.041404321789741516, 0.6309895515441895, -0.33304303884506226, 0.4316886067390442, 0.13154247403144836, 0.0034031840041279793, 0.33168256282806396, -0.009785903617739677, 0.3467365503311157, -1.2171393632888794, -0.7303896546363831, -0.909762978553772, 0.04315895959734917, -0.6252453327178955, 0.8955991864204407, 0.1763571947813034, -0.46513956785202026, 0.8612013459205627, -0.027388863265514374, 0.07967054843902588, 0.8538691997528076, -0.36814939975738525, -0.9989116787910461, -0.06960104405879974, -0.15623639523983002, -0.5063570737838745, 0.19781240820884705, -0.9987356066703796, 0.3113223612308502, -0.5513952374458313, 0.02004498429596424, 0.15895003080368042, 0.5700265169143677, 0.5498745441436768, 0.9967894554138184, -1.073773980140686, 0.3840172588825226, -0.034520916640758514, 1.0835274457931519, -0.8362024426460266, -0.9204147458076477, 0.5607675313949585, -0.48648136854171753, 0.10690989345312119, -0.3206038177013397, -0.700018584728241, 0.5078604817390442, -0.3729870915412903, 0.36027273535728455, 0.050252288579940796, 0.4312742352485657, -0.5708381533622742, 0.4917086064815521, -0.9429726004600525, 0.10350200533866882, -0.47649601101875305, 0.6035041809082031, 0.26657184958457947, -0.3618755042552948, -0.23329214751720428, 1.0365426540374756, 0.7039171457290649, -0.8067291378974915, 1.0347211360931396, 0.5587098002433777, -0.6965008974075317, 0.3318104147911072, -1.1020238399505615, 0.015216011554002762, 0.2937866151332855, 0.924733579158783, 1.3193787336349487, -0.544766902923584, 0.6760788559913635, 0.04986109957098961, -0.018336040899157524, -0.2514813542366028, 0.8639162182807922, 0.09194071590900421, -0.19742895662784576, 0.2145977020263672, -0.24554580450057983, 0.3134181797504425, -0.46908316016197205, -0.2879594564437866, -0.28809067606925964, -0.364583283662796, -0.41740682721138, -0.168666809797287, -1.087999939918518, 0.7134878635406494, 0.21462813019752502, -0.30216214060783386, -0.29860720038414, 0.18792815506458282, 0.5384713411331177, 0.47606635093688965, 0.34588423371315, 0.586468517780304, -0.06285928189754486, 0.9015032052993774, -0.2840466797351837, 0.2420910894870758, -0.1540571004152298, 0.86220782995224, -0.5726196765899658, 0.4720420241355896, 0.5396490097045898, 0.23433636128902435, -0.27081727981567383, 0.1056889221072197, -0.5335864424705505, 1.3397772312164307, -0.5470097064971924, 0.3154131770133972, 0.4203683137893677, -0.7500573396682739, -0.08444372564554214, -0.7950679659843445, 0.6421546936035156, -0.5033724904060364, -0.6432105302810669, 1.0756789445877075, -0.019756697118282318, -0.10542978346347809, 0.5851560831069946, -0.22981669008731842, 0.32260727882385254, -0.14925800263881683, 1.3517338037490845, -0.2656533122062683, 1.0750794410705566, 0.5450531840324402, -0.15782415866851807, -0.14141057431697845, -0.35550323128700256, -0.28963834047317505, -0.6635740995407104, -0.12305296957492828, -0.21250611543655396, 0.13265761733055115, -0.8650079369544983, -0.40749362111091614, 0.1578654795885086, 1.2946243286132812, -0.31460434198379517, -0.9648988246917725, 0.44554853439331055, -0.08004393428564072, -0.2938636541366577, 0.016130618751049042, 0.2583732008934021, 0.38792216777801514, -0.3584769666194916, -0.5635664463043213, -0.6503725647926331, 0.049272432923316956, -0.5021443963050842, -1.379217505455017, 0.3309842348098755, -0.318268746137619, -0.7604924440383911, -0.4019096791744232, -0.209369957447052, -0.5269927978515625, 0.13459256291389465, -0.17872737348079681, -0.25953635573387146, 0.667134165763855, 0.6353020071983337, -0.37915533781051636, 0.8521823883056641, -0.4538201689720154, 0.44271230697631836, 0.4002021253108978, 0.8498103022575378, 0.1532239019870758, 1.1830511093139648, 0.9545581936836243, 0.08379766345024109, 0.1699470579624176, -0.4966212809085846, 0.699977457523346, 0.003445735201239586, -0.38763633370399475, -0.45747286081314087, -0.7076521515846252, -0.6813764572143555, -0.36099720001220703, 0.19485193490982056, 1.131025791168213, 0.08211260288953781, -0.6525271534919739, -1.0743358135223389, -0.3133333921432495, -0.5354252457618713, -0.3151496946811676, -1.029080867767334, 0.7991209626197815, -0.24097701907157898, -0.4486373960971832, 0.13783766329288483, -1.4626399278640747, 3.2320690155029297, 1.4751147031784058, 0.8498718738555908, 0.09530621767044067, 0.22151900827884674, 1.1385148763656616, 0.9380276203155518, -0.7982848882675171, 0.2784656286239624, -0.5719703435897827, 0.7355403304100037, 0.09475700557231903, -0.08619026839733124, 0.41078829765319824, -0.047103509306907654, 1.1142234802246094, -1.031026840209961, -0.09650658071041107, 0.5065122842788696, -1.398404836654663, -1.0704712867736816, 0.3110961318016052, 0.1524268537759781, 0.17887061834335327, -0.0697096437215805, 0.45641908049583435, -0.12574268877506256, -0.3991549015045166, -0.511892557144165, -0.8167210817337036, 0.5638856291770935, -0.6153993606567383, 0.6816140413284302, 0.15138384699821472, -0.3635857403278351, 0.5876158475875854, 0.07618536800146103, -0.02571960538625717, 0.07142787426710129, -0.10534139722585678, 0.27826887369155884, 0.555557131767273, 0.6506180763244629, -0.7170498967170715, 0.480666846036911, 0.3326105773448944, -0.7016152739524841, -0.41057008504867554, 1.0024666786193848, -1.1353554725646973, 0.8127914071083069, -0.10268011689186096, 0.8704947233200073, -0.18620650470256805, -0.4783272445201874, 0.008335482329130173, 0.4989979863166809, -0.22186815738677979, -0.16572971642017365, 0.4039691090583801, -0.23198077082633972, 0.45980149507522583, -0.0026604272425174713, 0.11726520210504532, -1.3639370203018188, 0.19472770392894745, 0.0951928049325943, 1.0123207569122314, -0.1809975802898407, 0.0816001370549202, -0.24123544991016388, -0.6951990723609924, 0.07283332943916321, -0.8029072880744934, -0.03430536389350891, 1.0420398712158203, 0.05796892195940018, 0.037070464342832565, 0.7387962341308594, -0.6395213007926941, 0.3070412278175354, -0.05586154758930206, -0.46264952421188354, -0.0015075616538524628, 0.3956550657749176, 0.995462954044342, -0.544090211391449, -0.566123902797699, -0.7028325200080872, 1.0371394157409668, 0.9982403516769409, 0.42425283789634705, -0.3511121869087219, -0.8149543404579163, -0.6810874938964844]}\n"
     ]
    }
   ],
   "source": [
    "# # 임베딩 예시\n",
    "# import ollama\n",
    "# exmaple_embeddings = ollama.embeddings(\n",
    "#   prompt=splits[10].page_content,\n",
    "#   model='mxbai-embed-large',\n",
    "# )\n",
    "# print(exmaple_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임베딩 함수화\n",
    "import ollama\n",
    "def get_embedding(prompt, model=\"mxbai-embed-large\"):\n",
    "    response = ollama.embeddings(prompt=prompt, model=model)\n",
    "    return response[\"embedding\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컬랙션 생성\n",
    "import chromadb\n",
    "\n",
    "client = chromadb.Client()\n",
    "\n",
    "collections = client.list_collections()\n",
    "wiki_exists = \"wiki\" in [collection.name for collection in collections] # 컬렉션 존재 확인\n",
    "\n",
    "if wiki_exists:\n",
    "  client.delete_collection(\"wiki\")\n",
    "  \n",
    "collection = client.create_collection(name=\"wiki\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서 임베딩하고 컬렉션에 저장\n",
    "for i, d in enumerate(wikidoc):\n",
    "  embedding = get_embedding(d)\n",
    "  collection.add(\n",
    "    ids=[str(i)],\n",
    "    embeddings=[embedding],\n",
    "    documents=[d]\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"위키백과:정책과 지침 - 위키백과, 우리 모두의 백과사전\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n본문으로 이동\\n\\n\\n\\n\\n\\n\\n\\n주 메뉴\\n\\n\\n\\n\\n\\n주 메뉴\\n사이드바로 이동\\n숨기기\\n\\n\\n\\n\\t\\t둘러보기\\n\\t\\n\\n\\n대문최근 바뀜요즘 화제임의의 문서로기부\\n\\n\\n\\n\\n\\n\\t\\t사용자 모임\\n\\t\\n\\n\\n사랑방사용자 모임관리 요청\\n\\n\\n\\n\\n\\n\\t\\t편집 안내\\n\\t\\n\\n\\n소개도움말정책과 지침질문방\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n검색\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n검색\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n보이기\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n계정 만들기\\n\\n로그인\\n\\n\\n\\n\\n\\n\\n\\n\\n개인 도구\\n\\n\\n\\n\\n\\n 계정 만들기 로그인\\n\\n\\n\\n\\n\\n\\t\\t로그아웃한 편집자를 위한 문서 더 알아보기\\n\\n\\n\\n기여토론\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n목차\\n사이드바로 이동\\n숨기기\\n\\n\\n\\n\\n처음 위치\\n\\n\\n\\n\\n\\n1\\n최상위 정책\\n\\n\\n\\n\\n\\n\\n\\n\\n2\\n'정책과 지침'이란?\\n\\n\\n\\n\\n\\n\\n\\n\\n3\\n준수\\n\\n\\n\\n\\n\\n\\n\\n\\n4\\n집행\\n\\n\\n\\n\\n\\n\\n\\n\\n5\\n문서 내용\\n\\n\\n\\n\\n\\n\\n\\n\\n6\\n정책과 지침은 백과사전의 일부가 아닙니다\\n\\n\\n\\n\\n\\n\\n\\n\\n7\\n채택 과정\\n\\n\\n\\n\\n채택 과정 하위섹션 토글하기\\n\\n\\n\\n\\n\\n7.1\\n제안과 채택\\n\\n\\n\\n\\n\\n\\n\\n\\n7.2\\n내용 변경\\n\\n\\n\\n\\n\\n\\n7.2.1\\n실질적인 변경\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n7.3\\n격하\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n8\\n같이 보기\\n\\n\\n\\n\\n\\n\\n\\n\\n9\\n외부 링크\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n목차 토글\\n\\n\\n\\n\\n\\n\\n\\n위키백과:정책과 지침\\n\\n\\n\\n108개 언어\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikidoc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"위키백과:정책과 지침 - 위키백과, 우리 모두의 백과사전\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n본문으로 이동\\n\\n\\n\\n\\n\\n\\n\\n주 메뉴\\n\\n\\n\\n\\n\\n주 메뉴\\n사이드바로 이동\\n숨기기\\n\\n\\n\\n\\t\\t둘러보기\\n\\t\\n\\n\\n대문최근 바뀜요즘 화제임의의 문서로기부\\n\\n\\n\\n\\n\\n\\t\\t사용자 모임\\n\\t\\n\\n\\n사랑방사용자 모임관리 요청\\n\\n\\n\\n\\n\\n\\t\\t편집 안내\\n\\t\\n\\n\\n소개도움말정책과 지침질문방\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n검색\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n검색\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n보이기\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n계정 만들기\\n\\n로그인\\n\\n\\n\\n\\n\\n\\n\\n\\n개인 도구\\n\\n\\n\\n\\n\\n 계정 만들기 로그인\\n\\n\\n\\n\\n\\n\\t\\t로그아웃한 편집자를 위한 문서 더 알아보기\\n\\n\\n\\n기여토론\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n목차\\n사이드바로 이동\\n숨기기\\n\\n\\n\\n\\n처음 위치\\n\\n\\n\\n\\n\\n1\\n최상위 정책\\n\\n\\n\\n\\n\\n\\n\\n\\n2\\n'정책과 지침'이란?\\n\\n\\n\\n\\n\\n\\n\\n\\n3\\n준수\\n\\n\\n\\n\\n\\n\\n\\n\\n4\\n집행\\n\\n\\n\\n\\n\\n\\n\\n\\n5\\n문서 내용\\n\\n\\n\\n\\n\\n\\n\\n\\n6\\n정책과 지침은 백과사전의 일부가 아닙니다\\n\\n\\n\\n\\n\\n\\n\\n\\n7\\n채택 과정\\n\\n\\n\\n\\n채택 과정 하위섹션 토글하기\\n\\n\\n\\n\\n\\n7.1\\n제안과 채택\\n\\n\\n\\n\\n\\n\\n\\n\\n7.2\\n내용 변경\\n\\n\\n\\n\\n\\n\\n7.2.1\\n실질적인 변경\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n7.3\\n격하\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n8\\n같이 보기\\n\\n\\n\\n\\n\\n\\n\\n\\n9\\n외부 링크\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n목차 토글\\n\\n\\n\\n\\n\\n\\n\\n위키백과:정책과 지침\\n\\n\\n\\n108개 언어\""
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get_collection(\"wiki\").get()['documents'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'집행\\n\\xa0위키백과:관리자 및 위키백과:차단 정책  문서를 참고하십시오.\\n위키백과 내에서 정책과 지침 집행은 사회적 상호작용과 비슷한 양상으로 흘러갑니다. 특정 편집자가 정책과 지침에 쓰여 있는 공동체의 총의를 어기는 경우 타 편집자가 처음에는 문서나 사용자 토론란에서 정책과 지침을 지켜달라고 요청할 수 있습니다. 시간이 지나도 지속적으로 위반한다면 관리자의 제재 요청이나 강제적인 수단에 맡길 수도 있지요.\\n특정 사용자가 공동체의 규범을 총체적으로 어기고 있다면 규범 준수를 위해 좀 더 빠르게 강력한 수단을 이용해야 합니다. 특히 정책 문서에 명시된 원칙을 지키지 않는 것은 대부분의 경우 다른 사용자에게 받아들여지지 않습니다 (다른 분들에게 예외 상황임을 설득할 수 있다면 가능하기는 하지만요). 이는 당신을 포함해서 편집자 개개인이 정책과 지침을 직접 집행 및 적용한다는 것을 의미합니다.\\n특정 사용자가 명백히 정책에 반하는 행동을 하거나 정책과 상충되는 방식으로 지침을 어기는 경우, 특히 의도적이고 지속적으로 그런 행위를 하는 경우 해당 사용자는 관리자의 제재 조치로 일시적, 혹은 영구적으로 편집이 차단될 수 있습니다. 영어판을 비롯한 타 언어판에서는 일반적인 분쟁 해결 절차로 끝낼 수 없는 사안은 중재위원회가 개입하기도 합니다.\\n\\n문서 내용\\n정책과 지침의 문서 내용은 처음 읽는 사용자라도 원칙과 규범을 잘 이해할 수 있도록 다음 원칙을 지켜야 합니다.'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # 컬렉션 쿼리\n",
    "# results = collection.query(\n",
    "#   query_embeddings=get_embedding(\"격하 과정에 대해서 설명해주세요.\"),\n",
    "#   n_results=1 #쿼리 결과로 가장 유사한 값 1개만 갖고오기\n",
    "# )\n",
    "\n",
    "# results['documents'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컬렉션 쿼리 함수화\n",
    "def query_collection(collection, embedding):\n",
    "    results = collection.query(\n",
    "        query_embeddings=[embedding],\n",
    "        n_results=1\n",
    "    )\n",
    "    return results['documents'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'집행\\n\\xa0위키백과:관리자 및 위키백과:차단 정책  문서를 참고하십시오.\\n위키백과 내에서 정책과 지침 집행은 사회적 상호작용과 비슷한 양상으로 흘러갑니다. 특정 편집자가 정책과 지침에 쓰여 있는 공동체의 총의를 어기는 경우 타 편집자가 처음에는 문서나 사용자 토론란에서 정책과 지침을 지켜달라고 요청할 수 있습니다. 시간이 지나도 지속적으로 위반한다면 관리자의 제재 요청이나 강제적인 수단에 맡길 수도 있지요.\\n특정 사용자가 공동체의 규범을 총체적으로 어기고 있다면 규범 준수를 위해 좀 더 빠르게 강력한 수단을 이용해야 합니다. 특히 정책 문서에 명시된 원칙을 지키지 않는 것은 대부분의 경우 다른 사용자에게 받아들여지지 않습니다 (다른 분들에게 예외 상황임을 설득할 수 있다면 가능하기는 하지만요). 이는 당신을 포함해서 편집자 개개인이 정책과 지침을 직접 집행 및 적용한다는 것을 의미합니다.\\n특정 사용자가 명백히 정책에 반하는 행동을 하거나 정책과 상충되는 방식으로 지침을 어기는 경우, 특히 의도적이고 지속적으로 그런 행위를 하는 경우 해당 사용자는 관리자의 제재 조치로 일시적, 혹은 영구적으로 편집이 차단될 수 있습니다. 영어판을 비롯한 타 언어판에서는 일반적인 분쟁 해결 절차로 끝낼 수 없는 사안은 중재위원회가 개입하기도 합니다.\\n\\n문서 내용\\n정책과 지침의 문서 내용은 처음 읽는 사용자라도 원칙과 규범을 잘 이해할 수 있도록 다음 원칙을 지켜야 합니다.'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quetion = \"격하 과정에 대해서 설명해주세요.\"\n",
    "embedding = get_embedding(quetion)\n",
    "data = query_collection(collection, embedding)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "격하 과정은 위키백과에서 정책과 지침을 집행하는 일련의 단계를 말합니다. 이는 사회적 상호작용처럼 작동하며, 위반 사항이 있을 때 다른 사용자가 먼저 정책과 지침 준수를 요청할 수 있습니다. 이러한 요청에도 불구하고 사용자의 행동이 계속 문제라면, 관리자가 개입하여 일시적 혹은 영구적으로 편집 권한을 차단할 수 있습니다. 중재위원회가 관여하는 영어판과 다른 언어판에서는 격하 과정이 더욱 복잡한 분쟁 해결을 위해 확대될 수도 있습니다.\n",
      "\n",
      "격하 과정은 정책과 지침의 문서가 명확하고 이해하기 쉬워야 한다는 것을 강조합니다. 이는 처음 읽는 사용자들이 정책 및 규범에 대해 쉽게 파악할 수 있도록 하는 것을 의미합니다. 이러한 명확성은 위키백과 내 질서 있고 협력적인 분위기를 유지하는 데 도움이 됩니다.\n"
     ]
    }
   ],
   "source": [
    "# # 출력\n",
    "# output = ollama.generate(\n",
    "#   model=\"MoonYoungSik\",\n",
    "#   prompt=f\"Using this data: {data}. Respond to this prompt: {quetion}\"\n",
    "# )\n",
    "# print(output['response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "격하 과정은 위키백과의 정책과 지침을 집행하는 과정 중 하나로, 특정 사용자가 공동체 내의 규칙이나 지침에 반복적으로 어긋나는 행동을 할 때 발생합니다. 이 과정은 일반적으로 다음과 같은 단계를 포함합니다:\n",
      "\n",
      "1. 정책 및 지침 알림: 다른 편집자들이 해당 사용자의 행동이 정책과 지침에 부합하지 않는다고 판단할 경우, 그들은 문서나 사용자 토론란에서 이를 지적하며 정책을 준수해 줄 것을 요청할 수 있습니다. 이는 문제를 해결하고 사용자가 자신의 행동에 대해 성찰하도록 하는 비공식적인 방법입니다.\n",
      "\n",
      "2. 관리자 개입 요청: 문제가 지속되거나 심각하다면, 편집자들은 해당 사용자의 행동을 관리자에게 보고하여 제재 조치를 취할 것을 요청할 수 있습니다. 이 단계에서는 관리자가 상황을 평가하고 적절한 조치를 결정합니다.\n",
      "\n",
      "3. 일시적 또는 영구 차단: 관리자는 위반 정도와 사용자의 전반적인 기여도를 고려하여 일시적 혹은 영구적으로 사용자를 차단할 수 있습니다. 이는 사용자가 일정 기간 동안 위키백과에 편집을 할 수 없게 만드는 강제 조치입니다.\n",
      "\n",
      "4. 중재위원회 개입 (해당 언어판에 따라 다름): 영어판을 비롯한 일부 언어판에서는 일반적인 분쟁 해결 절차를 통해 문제를 해결할 수 없는 경우, 중재위원회가 개입하여 사건을 조사하고 적절한 조치를 결정합니다. 이는 사용자의 차단 기간 연장이나 해제, 또는 추가적인 제재 조치가 포함될 수 있습니다.\n",
      "\n",
      "격하 과정은 위키백과에서 정책과 지침을 집행하는 중요한 부분으로, 모든 사용자가 공동체의 가치와 규범을 준수하도록 보장합니다. 이 과정에서 편집자들은 정책 문서와 지침에 명시된 원칙을 직접 적용하고 집행해야 합니다.\n"
     ]
    }
   ],
   "source": [
    "model = ChatOllama(model= 'MoonYoungSik', temperature=0)\n",
    "\n",
    "# Chain 실행\n",
    "# model.invoke(\"격하 과정에 대해서 설명해주세요.\")\n",
    "\n",
    "print(model.invoke(f\"Using this data: {data}. Respond to this prompt: {quetion}\").content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moon_mys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
